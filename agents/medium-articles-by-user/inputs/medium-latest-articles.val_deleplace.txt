
== Article 1
* Title: 'Go slices, deleting items, and memory usage'
* Author: 'Val Deleplace'
* URL: 'https://medium.com/google-cloud/go-slices-deleting-items-and-memory-usage-81419317db3d?source=rss-5c7fb9360a28------2'
* PublicationDate: 'Mon, 04 Mar 2024 12:30:33 GMT'
* Categories: memory-leak, golang, go, gcp-app-dev, memory-management

Go is one of the best choices for cloud applications. It’s fast, frugal, secure, and provides built-in concurrency. A single server instance can handle hundreds, or thousands, of concurrent users, for a very long uptime.I had the opportunity to contribute a small but important change in the Go standard library. It’s aiming at reducing the memory usage, making software more frugal and reliable.The most efficient services strive to not allocate any extra memory at all when handling each incoming request. This makes sense for some specific, limited processings, but is not always possible. We create objects, lists, maps, which often have a non-zero memory footprint in the heap. It is still valuable to minimize our memory usage, especially for objects that outlive the current user request. We don’t want our total footprint to grow after each request. Whether the memory usage is growing for a legit and useful purpose, or because of a memory leak, the server would frequently crash with an “out of memory” error (OOM).I love it when a programming language comes with a garbage collector (GC), because machines are just better than humans at managing memory. But even with a GC, it is still possible to create too many objects and keep them “alive” (when the program is still holding references to them), and end up in an OOM crash. Let’s be careful!I also love it when I can use a carefully designed abstraction from the standard library, rather than writing my own toolbox. This is what the slices package added in Go 1.21 is about: various utility functions to manipulate slices of any type.One of them is Delete:// Remove s[2], s[3], s[4] from the slice ss = slices.Delete(s, 2, 5)This is much nicer than the traditional way of deleting elements from a slice, before Go had generics and before the slices package existed:// Remove s[2], s[3], s[4] from the slice s s = append(s[:2], s[5:]...)But slices.Delete comes with a few gotchas:It does not allocate a copy of the original slice s. Instead, it modifies the slice in-place, reusing the same underlying array.Because it’s modifying the length of s, it needs to return a new slice (a new window on the same array). That’s how slices work.Accidentally ignoring the return value is a bug. This will trigger a go vet warning in Go 1.23.The underlying array never shrinks.The original slice s is now “invalid”. Its length is too large and its last elements are not useful data anymore. Any other slices sharing the same memory portion are now invalid as well.In Go 1.21, the objects referenced by pointers in the array “beyond the new length” would not be garbage collected either.The last gotcha caught my attention me because Go developers would not always be aware that, in a slice of pointers to large objects, using slices.Delete could leave some pointers alive in a now-invisible part of the underlying array.s = slices.Delete(s, 2, 5)result in Go 1.21In my opinion, this was a form of memory leak.This leak would not theoretically affect the program correctness, but it would lead to:performance issueshigher costs associated with memory usagehigher probability of OOM crash (which, in a way, is a correctness issue)One possible solution would be, after shifting (copying) the right part to the left, to set the rightmost “obsolete” elements to nil, and let the garbage collector do its job. For the sake of memory frugality, I wrote a formal proposal, implemented it, and published a detailed article about it.s = slices.Delete(s, 2, 5)result in Go 1.22I had initially envisioned a casual, obvious fix: “let’s set the tail elements to nil, just like the ArrayList class does in Java”. But the community was divided at first: for some people, the status quo was better. And in my journey I discovered lots of details that required careful attention: What about runtime performance? What about the elements beyond initial length, within capacity? The capacity cap(s) includes the extra space available after len(s). What about element types that contain both pointers and non-pointers? What about the subtle question of the “ownership” of the original slice? What about accidentally misusing the package API? And what about backward compatibility?Fortunately, even if the behavior change is user-visible (the zeroed elements are reachable), it is backward compatible:The documentation of slices.Delete did not specify if the “obsolete” elements would be modified or not. No promises were made. Codebases were not supposed to rely on this detail of the old behavior.In codebases audits, we found that all such occurrences of code relying on the old behavior were in fact misusing the API (e.g. by ignoring the return value of Delete).The documentation is now more explicit: Delete zeroes the elements s[len(s)-(j-i):len(s)].Now that Out of Memory errors are a bit less likely, it’s time to deploy our first Go service to Google Cloud Run :)Go slices, deleting items, and memory usage was originally published in Google Cloud - Community on Medium, where people are continuing the conversation by highlighting and responding to this story.

== Article 2
* Title: 'Pixel guessing : using Gemini Pro Vision with Go'
* Author: 'Val Deleplace'
* URL: 'https://medium.com/google-cloud/pixel-guessing-using-gemini-pro-vision-with-go-26f1beac3cf2?source=rss-5c7fb9360a28------2'
* PublicationDate: 'Thu, 25 Jan 2024 13:20:26 GMT'
* Categories: google-cloud-platform, machine-learning, golang, computer-vision, gemini

Pixel guessing : using Gemini Pro Vision with GoLet’s have fun with the vision powers of AI!Gemini is Google’s most powerful publicly available family of AI models. The Gemini Pro models are available in Google Cloud via the Vertex AI web console and via the SDK available in Python, Go, Java, and Node.js.Gemini Pro Vision is multimodal: you can provide as a prompt either some text, some images, or some videos, or a mix.A very popular use case for testing the model is word-guessing, where you provide a picture and ask “What does this picture look like?”. The model is pretty good at guessing what you’ve just sketched with a pencil (freehand drawing), or at guessing the contents and the context of a photo.(yes, I’m an artist)I was curious to explore the limits of what the model can “see” when we show it too little information: A low-resolution picture.What can you see here?What does the AI model see?⇒ Try the live demo: Pixel Guessing ⇐As a Go developer, I was eager to try and call the Google Cloud Vertex AI API from my Go code, using the brand new Go SDK. Here is how you can try it too!PrerequisitesCreate a Google Cloud project (or select an existing one)Visit Vertex AI API, and click ENABLEInstall gcloud, the Google Cloud SDKIn your dev machine’s terminal, run the following command:gcloud auth application-default loginand select the same Google account you’re using in the Google Cloud web console.Now, here is how I created my little demo.Text editor, with a bit of magicI’m using VS Code, and for the first time I tried an AI-powered assistant for code generation and code completion. I installed the Google Cloud Code extension, which integrates the Duet AI assistant, and proceeded with the required setup.After logging in and selecting my project, I was ready to go!This turned out to save me a lot of time on Go and Javascript coding. High quality code suggestions, taking a lot of relevant context into account. It often felt like it was reading my mind. How did Duet AI know I wanted to write these 4 lines next!! But hey, I’ll take’em. The UI was sometimes wiggly though (no big deal).For example, here is a great suggestion (gray text) for a standard Go server boilerplate:or this nice suggestion in Javascript, to handle an HTTP response:Cloud architectureMy approach is to deploy a Frontend and a Backend that communicate in JSON with the browser, and have the Backend call the Vertex AI service to query the Gemini Pro Vision multimodal model.The source code of the app (Frontend and Backend) is available at github.com/Deleplace/pixel-guessing .FrontendMy Frontend consists of HTML, CSS, JS that send requests to the backend to:Generate pixelated images (resized to low-resolution)Ask the Gemini Pro Vision model “What do you see in this pixelated picture?”BackendMy Go backend is hosted on Cloud Run.In essence, this is how I’m calling the Vertex AI service:import "cloud.google.com/go/vertexai/genai"var prompt = "What does this picture look like? Provide a short answer in less than 8 words."func guess(ctx context.Context, jpegData []byte) (genai.Part, error) {    client, err := genai.NewClient(ctx, "MY-GOOGLE-CLOUD-PROJECT-ID", "us-central1")    if err != nil {        return nil, fmt.Errorf("unable to create client: %v", err)    }    defer client.Close()    model := client.GenerativeModel("gemini-pro-vision")    model.Temperature = 0.4    img := genai.ImageData("jpeg", jpegData)    res, err := model.GenerateContent(        ctx,        img,        genai.Text(prompt))    if err != nil {        return nil, fmt.Errorf("calling GenerateContent: %v", err)    }    answer := res.Candidates[0].Content.Parts[0]    return answer, nil}To degrade an image into a lower resolution, I’m resizing it with the package draw:import "golang.org/x/image/draw"func resizeRatio(src image.Image, ratio float32) image.Image {    newWidth := int(ratio * float32(src.Bounds().Max.X))    newHeight := int(ratio * float32(src.Bounds().Max.Y))    dst := image.NewRGBA(image.Rect(0, 0, newWidth, newHeight))    draw.NearestNeighbor.Scale(dst, dst.Rect, src, src.Bounds(), draw.Over, nil)    return dst}func resize(src image.Image, newWidth int) image.Image {    ratio := float32(newWidth) / float32(src.Bounds().Max.X)    return resizeRatio(src, ratio)}Let’s run the server locally:GOOGLE_CLOUD_PROJECT=my-project-id-herego run .and deploy to Cloud Run:gcloud run deploy pixel-guess --source=. \ --region=us-central1 \ --max-instances=1“us-central1” is one of the regions where Gemini is supported. Choosing the same region for Cloud Run and for Vertex AI helps reduce latency.Cloud Run services are supposed to be stateless. My app stores some state for a few minutes when you upload a picture, resize it into many lower-resolution images, and ask Vertex AI to guess the contents. Instead of using a real database or a persistent file system, my sample app is just keeping the picture in memory. By setting max-instances=1, I’m ensuring that only one instance of the server is currently holding state in memory, and serving requests. Of course that’s fine for a small demo, not for a large scalable production service.How good are the results?Well, don’t take my word for it, go ahead and try it :)Your turn nowWhat would you build with a multimodal model that accepts images and videos?Learn more about multimodal models in Google CloudExplore the Vertex AI Go SDKPixel guessing : using Gemini Pro Vision with Go was originally published in Google Cloud - Community on Medium, where people are continuing the conversation by highlighting and responding to this story.

== Article 3
* Title: 'Cutting cost: stopping the Cloud SQL instance is not enough!'
* Author: 'Val Deleplace'
* URL: 'https://medium.com/google-cloud/cutting-cost-stopping-the-cloud-sql-instance-is-not-enough-c7e0bfe63e4d?source=rss-5c7fb9360a28------2'
* PublicationDate: 'Wed, 08 Mar 2023 22:04:01 GMT'
* Categories: cloud-computing, google-cloud-platform, google-cloud-sql, gcp-security-operations, cloud-billing

Google Cloud SQLIf you know me, you know I love paying less. Who doesn’t? When you look at the Google Cloud Free Tier page, you’ll notice that BigQuery has a generous free quota of 10 GB of storage and 1 TB of querying per month, but Cloud SQL is conspicuously absent from the list. A Cloud SQL shared micro instance starts at $9.37 per month.In a project, I had a Cloud SQL instance (MySQL flavor) used only for analytics purpose, which accounted for ~99% of the monthly bill.Excerpt from my monthly cloud billSo it was very natural for me to refactor the app code to write to BigQuery instead, then turn off the MySQL instance, and save $9 each month.However, I was somewhat surprised to discover that my subsequent bills had not decreased that much.That’s because when you turn off an instance having a public IP (the default setting), its IP is still “reserved”, and this reservation costs $6.72 per month!Holding an IP reserved for the turned off instance has a costAs the migration to BigQuery was successful, and I had a dump of the old MySQL database on my laptop, I eventually hit “DELETE” on the Cloud SQL instance. This time, the cost should be down for good!Cutting cost: stopping the Cloud SQL instance is not enough! was originally published in Google Cloud - Community on Medium, where people are continuing the conversation by highlighting and responding to this story.

== Article 4
* Title: 'Cost of a bool slice in Go'
* Author: 'Val Deleplace'
* URL: 'https://medium.com/@val_deleplace/cost-of-a-bool-slice-in-go-b7d7ba1d6dda?source=rss-5c7fb9360a28------2'
* PublicationDate: 'Mon, 17 Aug 2020 16:09:20 GMT'
* Categories: bitset, golang, data-structures, memory-improvement

How much memory do 10 million bools take up?Short answer10MB. This is 8x as large as the number of bits that I actually care about.DetailsIn Go all elements of a slice are addressable. The smallest addressable unit being the byte, a slice of bools looks in memory like a contiguous sequence of bytes, containing only 1 useful bit per byte.Memory representation of a large sliceThe slice header itself (1 pointer + 2 integers) is negligible: its memory occupancy is dwarfed by the size of the backing array.I suspected that on my 64-bit computer, the minimal addressable unit would be a 64-bit word, incurring a 64x overhead for each useful bit! Fortunately, bytes are still individually addressable, keeping the overhead to 8x.If you’re worried about such a waste of memory, have a look at 7 ways to implement a Bit set in Go to learn about more compact options to store a large number of bits.Zeroes and ones

== Article 5
* Title: '7 ways to implement a Bit set in Go'
* Author: 'Val Deleplace'
* URL: 'https://medium.com/@val_deleplace/7-ways-to-implement-a-bit-set-in-go-91650229b386?source=rss-5c7fb9360a28------2'
* PublicationDate: 'Mon, 17 Aug 2020 16:02:38 GMT'
* Categories: bitset, golang, performance, benchmark, data-structures

Some data is best modeled as a bit set. For example, the essential information about which students successfully passed a test, out of 3000 students, consists in 3000 bits (375 bytes only).3000 bits ≡ 375 byte ≡ 750 hex digitsIt turns out that Go doesn’t have a Bitset type in the standard library!Abstract type: interfaceFirst, let’s say that a Bitset can be any type that implements these 3 methods:type Bitset interface {    GetBit(i int) bool    SetBit(i int, value bool)    Len() int}It is not necessary in general to start with an interface type. However, it has some advantages and in our case will help comparing different implementations.The Len method returns a number of bits, however its exact semantics is left to the choice of each implementation. We’ll focus more on GetBitand Setbit, and on fixed-sized bitsets.Concrete implementationsSlice of booleansA []boolis a straightforward choice.type BitsetBool []boolfunc (b BitsetBool) GetBit(i int) bool {    return b[i]}func (b BitsetBool) SetBit(i int, value bool) {    b[i] = value}func (b BitsetBool) Len() int {    return len(b)}We create trivial methods in order to satisfy the Bitset interface.See the source on GitHub.This works well when the size is set at creation and remains fixed:bs := make(BitsetBool, M)This implementation is not compact, as it takes up 1 byte per bit in memory, which is an 8x overhead.However, it has advantages:very simple to implementsimple to reason aboutfast data accessDynamic slice of booleanstype BitsetBoolDyn []boolfunc (b *BitsetBoolDyn) SetBit(i int, value bool) {    if i &gt;= len(*b) {        b.grow(1 + i)    }    (*b)[i] = value}......See the full source.The same underlying type []bool can be used to define a bitset type able to automatically grow when needed. To achieve this, the methods have a pointer receiver, as they need to update the slice header when growing. Also, bound checks are added to GetBit and SetBit, as the given index is not expected to always be within current bounds.Map of booleanstype BitsetMap map[int]boolSee the full source.A map of bool is a natural dynamic Bitset. It must be created before adding elements, with an optional size hint:bs := make(BitsetMap)orbs := make(BitsetMap, M)An interesting property is that if the Bitset is sparse (lots of false values), then the memory taken up by the map will be proportional to the number of true values, not to the potentially big highest index of a true value.Big Integer*big.Int implements the basic Bitset functionality, and automatically grows when needed.See this source which encapsulates a *big.Int.It is internally backed by a []uint, and its implementation details are more about arithmetic than about storing raw bits.Slice of bytestype BitsetUint8 []uint8func NewUint8(n int) BitsetUint8 {    return make(BitsetUint8, (n+7)/8)}func (b BitsetUint8) GetBit(index int) bool {    pos := index / 8    j := index % 8    return (b[pos] &amp; (uint8(1) &lt;&lt; j)) != 0}......See the full source. In Go, the types byteand uint8 are strictly equivalent.Bytes are the smallest addressable units in Go, so this implementation is compact: each byte is encoding 8 bits, and all bytes are contiguous in memory.Each Get or Set access requires a small computation to locate the correct byte, and access the correct bit inside the byte.Slice of 64-bit integerstype BitsetUint64 []uint64func NewUint64(n int) BitsetUint64 {   return make(BitsetUint64, (n+63)/64)}......See the full source.Modern computers are often 64-bit platforms, so it makes sense to try to achieve compactness and speed by storing data in 64-bit words (8 bytes).The implementation logic is the same as for []uint8.Package willf/bitsetimport wb "github.com/willf/bitset"type BitsetWillf struct {    wb.BitSet}See the source encapsulating willf’s data structure.This is a popular, ready-to-use bitset package. It has many useful features (popcount, union, etc.).The Bitset is implemented internally as a slice of uint64 plus an exact length in bits.BenchmarkThe source of my benchmarks are on GitHub: the 4 filenames containing “bench”.As always with benchmarks, don’t take the results too seriously. YMMV.Perf of write operationsSlice types []bool, []uint8, []uint64 are the fastest structures to write to. They are slightly faster than willf.Bitset, but also less sophisticated (they are fixed-sized, while willf’s embeds some auto-extend code that might not be inlined).Big integers and maps of booleans, though nice and easy to use, are slower.Perf of read operationsThe read operations numbers are more similar to each other. They are faster than write operations.It turns out that []uint8 and []uint64 have the same memory compactness and the same read and write performance numbers. No 64-bit premium gain after all!Cost of the Bitset interface abstractionIt may be more efficient to use a specific Bitset’s “raw” concrete type in a tight loop for reading or writing bits, than the Bitset interface type. Consider the difference between BenchmarkUint8IfcWrite and BenchmarkUint8RawWrite:var M = 100000func NewUint8(n int) BitsetUint8 {    return make(BitsetUint8, (n+7)/8)}func BenchmarkUint8IfcWrite(b *testing.B) {    bs := NewUint8(M)    benchmarkWrite(bs, b, M)}// Helper benchmark func, compatible with all implementationsfunc benchmarkWrite(bs Bitset, b *testing.B, n int) {    for i := 0; i &lt; b.N; i++ {        for j := 1; j &lt; n; j += 7 {            bs.SetBit(j, true)        }        for j := 1; j &lt; n; j += 7 {            bs.SetBit(j, false)        }    }}func BenchmarkUint8RawWrite(b *testing.B) {    bs := NewUint8(M)    for i := 0; i &lt; b.N; i++ {        for j := 1; j &lt; M; j += 7 {            bs.SetBit(j, true)        }        for j := 1; j &lt; M; j += 7 {            bs.SetBit(j, false)        }    }}For slices of bytes, the “raw” concrete version is 2x as fast as the “ifc” version.For slices of booleans, the “raw” concrete version is 5x as fast as the “ifc” version!The interface abstraction has a high cost when:each method does a very small amount of work,methods are called on an interface variable in a tight loop, forcing the conversion to the concrete type over and over,compiler optimizations such as inlining, constant propagation, bounds check elimination, are not possible at all without knowing the concrete type.In the two famous interfaces Reader and Writer from package io:type Reader interface {    Read(p []byte) (n int, err error)}type Writer interface {    Write(p []byte) (n int, err error)}the methods take a slice as argument, so it’s possible to have them do a large amount of work in a single call. This is not the case with our GetBit, SetBit abstractions which deal with a single bit at a time.When benchmarking the “raw” concrete type BitsetUint8,..../bitset_bench_write_raw_test.go:76:13: inlining call to BitsetUint8.SetBit method(BitsetUint8) func(int, bool) { pos := index / 8; j := uint(index % 8); if value { b[pos] |= uint8(1) &lt;&lt; j } else { b[pos] &amp;= ^(uint8(1) &lt;&lt; j) } }...the short methods GetBit and SetBit are inlined, which saves the cost of a function call. This in turns lets the compiler perform other optimizations, possibly discovering that all slice indices are inferior to M, and eliminating some bound checks.If we want to benchmark each concrete type, we need to write the benchmark code for each of them, as it’s not possible to just call the helper func benchmarkWrite, which would skew the results.This is actually an important lesson: if performance is really important to you, and you’re calling an interface method millions of times in a tight loop, then you should consider working with a concrete type instead.Usually though, it’s fine and useful to abstract some behaviors in an interface type.Fixed size or dynamic growthThe simple versions of the slice types ([]bool, []uint8, []uint64) are assumed to have fixed size at creation time.All other implementations are dynamic: *big.Int, map[int]bool, willf.Bitset.Turning a “fixed-sized” slice type into a dynamically growing slice type is not very complex: use a pointer receiver in methods, and add explicit bound checks.In my benchmark results, I reckon that the overhead of the bound checks is actually very small.Using the fixed-size version or the dynamic version would depend on the intended use case, as very often a fixed-size bitset is really what we need.One use case needs special attention, and a trade-off:either growing for index i is implemented by allocating a new slice to hold (i+1) bits. This is a “compact” way of growing, however if you start with an empty slice, and then flip some n bits incrementally from lower indices to large indices, you will end up with an extremely slow O(n²) runtime complexity. This must be avoided.or growing for index i is implemented with append, which “reserves” ~25% of extra unused capacity, in order to achieve a much more sensible cost O(n) when flipping n bits.Go versionsIt’s easy and useful to install several versions of Go on one’s computer (example in bash):for i in {10..15}; do  go get golang.org/dl/go1.$i  go1.$i downloaddoneNow I can run the benchmark on 6 major releases of Go, and look for differences.Full benchmark run of Go 1.10 up to Go 1.15 — Smaller is betterFirst, most of the lines are dwarfed by 2 outliers, which are “writing bits to *big.Int in Go 1.10”. This part seems to have been tremendously optimized in Go 1.11!Let’s zoom in.The 2 lines above 400μs/op are “writing bits to map[int]bool”.So far, we know that big ints and maps are not the most efficient for writing.Let’s zoom in further.While the chart still looks a bit messy, we can notice many peaks on Go 1.11, as if this specific release was less efficient than the previous ones and than the subsequent ones.If we focus on Go1.12 and above, then we notice less dramatic changes from one Go version to another.Benchmark run of Go 1.12 up to Go 1.15 (*big.Int and map[int]bool are cropped by zooming)Comparing Go releases with regard to a benchmark is interesting because relying too much on the performance shape of some niche implementation details sometimes lead to “fragile” micro-optimizations, that may no longer hold with the next major release of the compiler.ConclusionA Bitset is conceptually a simple object, that can be implemented using one of several backing types.Using a fundamental data structure is not always about importing a package, it’s also fine to write one’s own implementation. One important thing is to understand the trade-offs.Not everything is big data, and not every use case needs peak runtime performance or perfect memory compactness. However, being legible and intelligible is always extremely valuable, so if you need a Bitset, my advice is to choose one that’s simple to use and hard to misuse. I have a preference for the slice of booleans. Your choice may be different :)What can we do with a Bitset? Bloom Filters, of course! That would be a story for another post…

== Article 6
* Title: 'App Engine under heavy load'
* Author: 'Val Deleplace'
* URL: 'https://medium.com/@val_deleplace/app-engine-under-heavy-load-8fa40a33d531?source=rss-5c7fb9360a28------2'
* PublicationDate: 'Fri, 28 Feb 2020 09:58:44 GMT'
* Categories: bigquery, google-app-engine, google-cloud-platform, memorystore, xss-vulnerability

Yesterday I opened the Logs page of my App Engine Standard application in the Google Cloud console to check a specific log, only to discover much more traffic than I expected.Unexpected logs: many requests per secondConfirmation in the App Engine “Summary” dashboard:50 req/s. That’s a lot.“50 requests per second” is definitely not the traffic from my real users. The real traffic usually looks like this:0.1 req/s. That’s the usual load.It’s also not caused by search engine crawlers and spam bots. And (this time at least) it’s also not caused by my negligence in letting a test load injection script run forever from my workstation, or a failing background task retrying forever server-side in the cloud.The culpritSo, what is this about?Spikes last longer than usualIt turns out that I have an “IT dept security thing” that finds it appropriate to bombard my app with thousands of shady requests on a regular basis, just to see what happens. This usually runs once a week, lasts for 2 hours (A), and that’s it. When the blitz traffic is ongoing, it dwarfs the “real user traffic” so much that we can’t even see the real traffic anymore in the charts.Now the security thing spikes (B) seem to be willing to run for 9+ days in a row, which is clearly unusual.The security tool did find something useful: By injecting malicious URL parameters, it was able to trigger a JS pop-up in the application, and reported it in the issue tracker. This is a potential vulnerability that I will fix right away. And (as far as I understand) this is why it kept searching for days and days, rediscovering the same, or very similar, vulnerability.This is a happy story. There security tool found a bug and caused no harm despite its offensive strategy:There was no service disruption. Nobody was aware that the security tool was running for much longer than usual. The App Engine autoscaler spawned enough concurrent stateless instances to handle the traffic gracefully.Autoscaling working just fineThe security tool did not accidentally destroy any data. This is because only registered users have write access to the data, and that policy held true during the traffic spike.There was no spike in real usage error rate. Only a spike in 4XX response codes sent back to the numerous invalid requests:The extra cost incurred by App Engine instance was acceptable (i.e. cheap).I didn’t set any monitoring pager alerts in this project, so nothing woke me up in the middle of the night.Minor impact?I mentioned that we didn’t experience any service disruption, that no user was aware that anything abnormal was going on, and that the cloud scaling capability shone.The app uses a Cloud SQL database accepting only a limited number of simultaneous connections, but we didn’t hit this limit because (I suspect) most of the traffic was either immediately rejected, or was served cached content without calling the database.We use Memorystore Redis as fast server cache, with 1GB capacity which is plenty for our data. We have ~2,000 valid paths (URLs) generating each less than 100KB of JSON, and we store the (path, data) pairs for a while, which usually accounts for a few hundreds cache entries at any given time.It turns out that the security traffic consists in many invalid requests, but also many valid requests, which end up with a 200 code and the (path, data) saved in cache.The server cache memory usage chart follows the traffic spike timeline:and it looks like the 1GB limit is not hit very often, so it should not impact the app performance in a negative way.But actually, if we zoom a bit to the last 2 days window:…we see that the cache is very often saturated and flushed.Let’s use BigQuery to dig a bit deeper! Having all the logs exported to BigQuery is very useful, and I highly recommend creating a “sink” in most projects.SQL to mine request count and latencyTo reveal the real user traffic, I filter out requests from the security tool, based on the user agent string. The resulting daily traffic is too small and noisy to be statistically significant, which is why I’m grouping the results by week.This provides me with a data grid that I can now save in Google Sheets……to produce this chart:My reasoning is: if the security tool (weeks 7, 8, 9) had significantly perturbed the server cache, then the cache hit ratio would have plummeted for the actuel user requests, and the mean service time would have increased.Here we see that the (real user traffic) latency may have grown from 240ms to 275ms during the “security tool blitz” weeks, but the delta is too small to conclude anything for sure.Bottom line, the service was not degraded in any meaningful way. That’s a win for Google Cloud’s infrastructure.

== Article 7
* Title: 'Tiny evil factor'
* Author: 'Val Deleplace'
* URL: 'https://medium.com/@val_deleplace/tiny-evil-factor-46a34d5e5b60?source=rss-5c7fb9360a28------2'
* PublicationDate: 'Wed, 11 Dec 2019 21:11:26 GMT'
* Categories: programming, algorithms, big-o-notation, computer-science

Have you ever tried to design an algorithm to solve a problem on an input of arbitrary length n, and nailed it in only O(n) running time?Sometimes it’s easy, like “Find the minimum in the following list of n integers”A decorative asymptoteThe inconvenient truthMost of the time you actually don’t end up with a true O(n), but rather with O(n log n).Think about it : whenever you can’t simply “look at an item and immediatly throw it away”, you’re pretty doomed. You need a random access to the n data, or at least be able to refer to each item individually. In order to refer to n elements, you need indexes or pointers of size (log n). QED.So what?The above realization doesn’t change anything to the actual performance of your favorite lines of code. It does however shed some light on two aspects of logarithmic factors.A useful rule of thumb : (log n) grows so slowly that you may as well regard it as a constant factor and wipe it off the theoretical equation. In real computers, we use 32-bit or 64-bit pointers. You might sometimes want to index up to 2⁶⁴ items stored somewhere on earth. If you’re a Big Data company, you might want to index more than 2⁶⁴ physical items. But you will never want to index up to 2²⁵⁶ real-life objects, no matter what. Consider 256 as an upper bound constant.Big-O analysis is fundamental but doesn’t tell the whole story. It ignores all “constant factors”, more precisely all factors having an upper bound that does not depend on the size of the input. As if the Jeff Dean numbers had all the same value! In real life, these hidden factors matter a lot. Take them into account. The (log n) factor is “just one of them”, in the sense that the value of its hidden multiplier matters much more than the fear of (log n) itself growing very high. It won’t.

== Article 8
* Title: 'A sample of source transformation of Go code'
* Author: 'Val Deleplace'
* URL: 'https://medium.com/@val_deleplace/a-sample-of-source-transformation-of-go-code-c96a6ab2b47c?source=rss-5c7fb9360a28------2'
* PublicationDate: 'Thu, 17 Oct 2019 09:01:17 GMT'
* Categories: golang, programming

gofmt is not only about formattingTL;DR$ gofmt -w -r 'strings.Index(a, b) &gt;= 0 -&gt; strings.Contains(a, b)' .What I was trying to achieveUntil recently, Javascript didn’t have the includes method to test if a string b is a substring of a string a. The idiomatic way to test this wasif (a.indexOf(b) !== -1) {  // b is a substring of a} else {  // a does not contain b}This doesn’t apply to Go, as we’ve always had string.Contains. However, it’s still possible to find the aforementioned JS idiom in a Go codebase:    if strings.Index(s, "-") &gt;= 0 {        // ...    }Now I’d like to replace all occurrences of this form by the idiomatic call to strings.Contains.I could do it by hand, but there are many occurrences in my project, so this would be tedious and error-prone.Ctrl+Shift+H (or other favorite editor’s replace command) won’t directly do this, as it’s not a simple string replacement. I need to replace “strings.Index“ with “strings.Contains”, and preserve the two arguments, and remove the “&gt;= 0”.Some text editors or IDEs offer a replace feature with regexp matching and replacement with numbered matching fragments. This would probably work in this case, but I don’t recommend doing complex things with (illegible) regular expressions in the general case.I hear IntelliJ IDEA has a “Structural search and replace” feature. I’ve not tried it yet.Enter gofmtThe blog post go fmt your code shows how “gofmt” can be used to perform mechanical source transformation. This is exactly what I needed!I found a few variants of the non-idiomatic form, so I took care of all of these:$ gofmt -w -r 'strings.Index(a, b) &gt;= 0 -&gt; strings.Contains(a, b)' .$ gofmt -w -r 'strings.Index(a, b) &gt; -1 -&gt; strings.Contains(a, b)' .$ gofmt -w -r 'strings.Index(a, b) != -1 -&gt; strings.Contains(a, b)' .Yay!!

== Article 9
* Title: 'Surviving traffic spike from Hacker News: my dreaded Google Cloud invoice'
* Author: 'Val Deleplace'
* URL: 'https://medium.com/google-cloud/surviving-traffic-spike-from-hacker-news-my-dreaded-google-cloud-invoice-6b940dd9eba6?source=rss-5c7fb9360a28------2'
* PublicationDate: 'Wed, 09 Oct 2019 09:34:45 GMT'
* Categories: scalability, app-engine, google-cloud-platform, golang, hacker-news

This story relates events that happened on September 26th, 2019. They are all true. A website that I built, “Programming Idioms”, hit the first page of the “orange site” (aka Hacker News). My cloud provider monitoring console let me find out if the sudden traffic had caused an outage or not. And the invoice a few days later taught me that running a service in the cloud is not a free meal.Disclaimer 1: I currently work for Google Cloud. However, I had designed and deployed the website Programming Idioms before joining Google.Disclaimer 2: This is a faithful report of my specific experience. It obviously doesn’t apply to any unrelated similar cloud projects. YMMV.1. SymptomsAt 5:07 PM, I receive a notification: Someone is asking to add support for their favorite programming language in my website. Then five minutes later, another notification, from someone else, asking for the same language. What’s going on?On Programming Idioms, writing a snippet in a non-supported language results in a pleasant, vintage error page:A pleasant, vintage error pageI decide to log into the Google Cloud Platform (GCP) web console to check if many such errors have recently occurred. The contribution system might be broken for some reason.The first thing I notice is an unusual shape in the “requests per second” dashboard. I also notice a high instance count.Unusual # of requests per secondUnusual number of server instances currently runningMy first thought is that I made a blunder like an infinite loop of failing tasks launched by a cronjob. I have to fix this right away! Infinite loops in the cloud are not good for the bank account.At this point, it is useful to know that GCP does not provide yet a simple way to cap the cost of a given Project, i.e. to automatically prevent the billed $$$ from skyrocketing. This would, however, be nice to have, to say the least.At a Project level, it is possible to set up “Budget Alert” emails when the cost exceeds some specified thresholds. But in the case of my script running amok and wreaking havoc (or a genuine sudden spike of traffic), I will most probably read the mail and take action after a lot of cash has already been burned.Nevertheless, at the App Engine Standard level there is a “Daily spending limit” option. Good to know!This option could save your retirement planEdit: At the Service level (GCP component), you can learn an effective way to Set up cost controls with quota. This covers a large share of all possible bad scenarios.I was not thinking of a huge influx of visitors, yet.My experience with scalability of web services is that uncertainties around expected traffic volume are often addressed with ambitious defensive designs and over-provisioning, following advice and wisdom from this great book:Credits: ThePracticalDev on TwitterBasically, entrepreneurs have a high opinion of the probability of their service going viral and successful, and care a lot about being able to handle the inevitable huge load, before other crucial concerns. In my opinion, market research, UI, UX, usability, having a MVP, gathering early feedback, etc. are more pressing than dealing with a million concurrent users. Success will come eventually (or maybe not at all), successive waves of traffic increase will happen, and each significant increase will be an opportunity to revise the scalability strategy, taking the actual traffic and error monitoring metrics into account, as well as a better understanding of the needs of the project (than early in the prototyping phase).I acknowledge however that an unexpected exposure in popular media is a tangible threat. Nobody wants their service to fail when a spike of traffic does happen. Actually, it’s the worst time to go down!In my case, Google Analytics confirms an unusual influx of visitors:# of sessions per hourThe traffic per hour before the spike is definitely not zero (~6000 sessions per month is ~8 per hour, on average). It’s simply dwarfed by the magnitude of the spike.The culprit is just a few clicks away, in the “Acquisition” section:Now that I understand what is going on, I want to know if the service quality is suffering from the load.2. ArchitectureProgramming Idioms uses the following infrastructure components:App Engine with a Go language environmentDatastore, a NoSQL databaseMemcache, a distributed in-memory data cacheThese components per se are scalable: App Engine spins up as many stateless web server instances as needed (autoscaling, yay), and the Datastore has “a distributed architecture to automatically manage scaling”.This doesn’t automagically mean that my website won’t crumble under the load. Careful design and implementation are needed to correctly leverage the scalability of the platform. My main challenge is data consistency: Programming Idioms accepts contributions from anyone without needing to create an account, and I have to take care of edit conflicts when users are modifying the same “idiom” at the same time.I designed the website using a few performance optimization techniques, with responsiveness in mind, which also happen to decrease the costs:FrontendGzip is enabled for all responses.JS is concatenated and minified into a single file, which contains jQuery, Bootstrap, Prettify, and my own JS code.The JS file is included at the bottom of the HTML.CSS is concatenated and minified.All static files are served with a very long public cache header. Updating the static files is done through a revving technique: Whenever I modify a static file, I bump the virtual folder of static assets, implicitly invalidating obsolete resources in the browser cache and server cache.The website is mostly text, with a limited number of small images.All the pages are server-side rendered. Per my measurements, templating is reasonably fast and is not the bottleneck. The alternative (client-side rendering) would involve JSON marshalling, which is not free either.All static resources are declared as “static_dir” in app.yaml, which means that they are served by an efficient distributed CDN, and don’t use my App Engine server instances at all.The number of HTTP requests is kept small: 10 requests for a page, out of which 8 responses (static assets) go to the browser cache and don’t need to be requested anymore.BackendThe Datastore is a NoSQL document database. I have ~180 “idioms” containing ~3000 snippets. Each idiom is stored as one document containing several snippets. The rate of reads will by far exceed the rate of writes.Accessing Memcache is orders of magnitude faster than accessing the Datastore. As I have a grand total of ~2MB of data, I aggressively store all the snippets in Memcache.A modification of a snippet must invalidate the snippet in the cache. Cache invalidation is reputed to be hard. My strategy consists of selectively evicting all cache entries related to the modified element (but not flushing the whole cache on every write operation).Generating a page from an HTML template is fast, but still incurs some work. I decided to aggressively cache (in Memcache) all the HTML pages.Indexing is important for search, but is not allowed to slow down the handling of a request. I delay the indexing work, which will be put in a task queue and executed outside the scope of the user request.I keep a history of all the successive versions of all the snippets, but writing to the history is a non-pressing concern which is also delegated to a background task queue.Go is a nice choice for App Engine standard because the clones start very fast and the runtime has a small memory footprint. A single instance of the smallest class F1 is usually more than enough to serve many concurrent visitors.External API calls (e.g. to the database) are usually the latency bottleneck in the processing of a web request by a serverless instance. Thus, it makes sense to leverage goroutines and waitgroups to launch several API calls concurrently, as they are network-bound, not CPU-bound. I actually don’t need to do this for the idiom view page, however I do use concurrency to improve the text search experience.A server instance vCPU spends a lot of its time idle, even when serving several concurrent requests, because most of the latency is spent waiting for external components. This is an example; I don’t use GCS and Pub/Sub in this project.For further insights about Go and cloud performance see this article and this video.App Engine comes with a generous daily free quota. In fact my usual 10K pageviews per month rarely reach a few percent of the quota.Slightly worried but not too much.This freebie somewhat “masks” the actuality of what will be charged when we exceed the quota. Little did I know what I would really be facing.But it’s not the time yet for money consideration, first I want to know if the service quality is suffering from the load.3. MonitoringThe [ERROR] level in the logging view is not too bad. Mostly a dozen occurrences of the “not a supported language” BSOD. So far, no abnormal error rate. (From a UX perspective, I should fix this, though.)ERROR level in the Stackdriver Logging viewThe [WARNING] level in the logging view is not too bad either. It mostly consists of a 404 for a minor missing image, oops. So far, no abnormal error rate.WARNING level in the Stackdriver Logging viewTo get detailed insights about the server-side performance, I usually go to the BigQuery interactive console:There, I discover that the logs for today are missing from BigQuery, and much later do I realize that a configuration glitch occurred during a migration to the go111 runtime just two days earlier. Oops. I still have the logs exported to Cloud Storage though, but the JSON files are a bit less convenient to dig through. ./jq is still a friend!In the Latency dashboard of App Engine, I can check the 50th, 95th, and 99th percentiles before and after the traffic spike.This looks bad but is actually pretty good, except for the 99th percentileThe median latency is always extremely low (~2ms) because the static files are served by a CDN-like system. This is good, but also not a very relevant metric.The 95th percentile figure is much more important to me, and it turns out it’s consistently below 100ms, which is fine.I should, however, check why the impressive turquoise line of the 99th percentile rose from 200ms before the 26th to ~1000ms after the 28th. Even if less than 1% of the requests hit that latency, a 5x jump is kind of worrying. It’s also intriguing that the degraded 99%’ kicks in one day after the spike, and then remains durably degraded well after the spike.A grid containing a square for each snippetIt turns out that all the slow requests are about displaying a specific page featuring a grid dynamically built out of the current state of the whole database: All idioms, all snippets.The grid data is cached server-side, and frequently updated. 65% of the time this specific request hits the cache and is fast, 35% of the time the grid gets regenerated and the response time is high.For some reason, the grid now takes 50% more time to serve, in the fast case (cached) and in the slow case as well. This may be related to having migrated recently to App Engine 2nd gen runtimes, though I’m not 100% sure at this point.The homepage and the idiom detail page are fine: From the server perspective, their latency has not been degraded during the traffic spike.4. The cleaverA cleaver (credits)Before the traffic spikeI receive an invoice every month. As I mentioned, the traffic (6K sessions, 10K pageviews) usually fits easily within the free quota. Thus App Engine, Datastore, and Memcache usually cost me zero.A typical month’s costI do have 5GB of non-crucial files in GCS (logs), which I could delete if I want to save 11¢.Have you noticed the $0.01 to write all my logs to BigQuery, for analytics? I highly recommend setting up this log export. BigQuery is great for log investigations.After the traffic spikeThe month of September saw a total of 44K sessions, 160K pageviews. 94% of them occurred after the 26th.Six days after the spike, I received the invoice for September:September 2019The infrastructure costs didn’t drive me to bankruptcy after all.Two things surprise me in the Out Bandwidth section:25GB seems like a lot, at first. Let’s do the math: 25GB/160K pages is 150KB per page, on average. This makes sense, as an idiom detail page view downloads 240KB gzipped (700KB uncompressed), and the homepage is slightly heavier (340KB). Subsequent pages with a warm cache are super-small: 15KB only!Static files in App Engine used to be served for free, if I remember correctly. I don’t know if it was a bug or a policy, but it seems not to be the case anymore. Static files probably account for ~95% of my 25GB of egress network traffic.Here I am, six dollars poorer, and impressed by a massive community of developers who came to have a look and stayed to contribute a snippet on their own — implementing a two-liner may look like a trivial no-brainer, but it is actually very time-consuming to write sensible code and link to the official documentation. I want to thank everyone, heartfully.If you’d like to contribute a snippet, here’s an entry point: Look at the grid, and find an empty circle in the column of a language you’re familiar with. I also encourage you to edit existing snippets to improve them.More tech, cloud, and go elucubrations on my Twitter! https://twitter.com/val_deleplaceSurviving traffic spike from Hacker News: my dreaded Google Cloud invoice was originally published in Google Cloud - Community on Medium, where people are continuing the conversation by highlighting and responding to this story.

== Article 10
* Title: 'Dancing gopher with Cloud Functions'
* Author: 'Val Deleplace'
* URL: 'https://medium.com/google-cloud/dancing-gopher-with-cloud-functions-ad5b5ce8676a?source=rss-5c7fb9360a28------2'
* PublicationDate: 'Thu, 24 Jan 2019 18:11:51 GMT'
* Categories: serverless, golang, google-cloud-platform, cloud-functions

The Beta support for Go 1.11 on Google Cloud Functions has been announced last week. Here are a few details about the Dancing Gopher factory function that I tweeted about.First, it’s easier to have some code already working on my local machine, before throwing it to GCF. A single source file is enough for a small sample like this one.My program does basically 4 things:Read a GIF fileChange the fur colorAdd a caption inside each frameWrite the updated GIF fileI can start with a command-line Go program (gist):Local program (abridged)It works, yay.The GIF codec is in the standard library. I achieve the fur color change (2 color values) by just modifying the indexed color Palette, instead of accessing the pixels:A Palette can be used as a colored lens…Writing some text in an image is not part of the stdlib. However there is a basicfont package in golang/x, let’s use it.The program doesn’t look like serverless magic though. It reads/writes on the local file system. And values for parameters Text and Color are hard-coded, yuck!Let’s turn this into an idiomatic Go server (gist):Web server (abridged)The server could read from its filesystem, however the next steps will be more straightforward for me if I copy the original GIF to Cloud Storage, make it public, and let my handler read it from its public URL.My local server is now very close to the format of a Google Cloud Function, except 2 things:the package can’t be “main”there must not be any “main” funcTurning the code into “just a Function”I can now create a new Function in the GCP web console by copy-pasting my file:I specify the name of my handler “MakeGif” and hit [SAVE], and a minute later my server is ready to produce dancing gophers. This is a single Function at a single URL, not a full webapp backend!As you can see, deploying a small piece of code to Cloud Functions is quite simple. My example could equivalently be deployed to App Engine, through a slightly different workflow.Note that when redeploying a Function, the old version will still be serving for a minute or so, and only then will the new version take over.Original dancing gopher animation by Egon ElbreDancing gopher with Cloud Functions was originally published in Google Cloud - Community on Medium, where people are continuing the conversation by highlighting and responding to this story.
