
== Article 1
* Title: 'Google Cloud Platform HTTP Load Balancers Explained via the CLI'
* Author: 'Ian Lewis'
* URL: 'https://medium.com/google-cloud/google-cloud-platform-http-load-balancers-explained-via-the-cli-4f4d61805297?source=rss-8660bca0444d------2'
* PublicationDate: 'Mon, 18 Apr 2016 02:56:33 GMT'
* Categories: google-cloud-platform

This is a post cross posted from my blog.The Google Cloud Platform Load Balancers are based off of technology that Google developed for our applications. There are two types of load balancers, the Network (L3) Load Balancer and the HTTP (L7) Load Balancer. The HTTP Load Balancer is global so the same IP can be used everywhere in the world, but still supports very high scalability with no warmup.Setting up the HTTP Load Balancer is fairly straightforward in the Developers Console. You can create one in the Networks section of the console and create a load balancer. Once you’ve started creating an HTTP Load Balancer, you get a page something like this:Each of the sections is nicely laid out and allow you to create the load balancer all at once. But there are many objects being created under the covers here, many of which only vaguely map to the UI. It can be a bit daunting to set up via the the Google Cloud CLI.The HTTP Load Balancer documentation has some good info and diagrams that help understand how it works. But I found the diagram there to be a bit too simplistic when I wanted to set up the load balancer via the CLI. I needed to know a bit more about all the parts so I came up with this diagram.Let’s go step by step through how to create the load balancer via the CLI. As we do that, I’ll try to point out what each of the objects we are creating correspond to in the Cloud Console so you have an idea where to look for them later.Health ChecksSince most of the objects depend on one another, we will need to go from “back” to “front” starting with health checks and backend services and ending with forwarding rules. The health check object doesn’t depend on anything else so we can create it first. Even though we create the object here, it only really becomes active after we attach it to a backend service.gcloud compute http-health-checks create my-healthcheck --host &lt;a href="http://www.example.com"&gt;www.example.com&lt;/a&gt; --port 80 --request-path=/healthzHere we create a health check that will connect to our app via port 80 at the /healthz URL. Note that creating the health check only tells further configuration the port and path to check but doesn’t actually send the health checks. The host parameter isn’t actually used as the host to connect to but only to set the Host header. Some apps check this header so we want them to be able to return a successful status. The instances to health check are specified later by the backend service.Health checks are used in more than one place so they live under the Compute Engine part of the Cloud Console UI. The health checks listed here are the what correspond to http-health-checks and https-health-checks in the CLI.Backend ServicesNext we’ll create a Backend Service. A backend-service object defines the backend VMs that actually serve the requests. The Backend Service contains a number of Backends. Each Backend is essentially a link to an instance group but has some other options attached like which port numbers to use and load balancing mode. The prefered way to set the port is via named ports on the instance group. You can set a named port for port 80 called http-port using the following command. I’m assuming you already have an instance group called my-instance-group set up. You can find out more about creating managed instance groups here.gcloud compute instance-groups set-named-ports my-instance-group --named-ports http-port:80Next you can create the backend service:gcloud compute backend-services create my-http-backend-service --http-health-checks my-healthcheck --port-name http-port --protocol HTTPNow that we have the health check attached to the backend service, it will connect to the instances specified by the backend service to do the health checks.The UI shows backend-services in the “backend configuration” part of the UI.Next we have to create a Backend. A Backend specifies the instance group you want to send traffic to, and how the load should be balanced among the available instances. You can create more than one backend and a backend is generally created one per instance group. You can use this to do cross-region load balancing for instance.gcloud compute backend-services add-backend my-http-backend-service --instance-group my-instance-group --balancing-mode RATE --max-rate-per-instance 10This sets up a backend that sends traffic to my instance group and uses the request rate as a way to load balance. I am setting it so that each instance will get 10 requests per second maximum but you can also set this up to use CPU utilization based on your needs.In the UI, backends are part of the backend service form. You can add any number of backends to the backend service just like can in the CLI.Url MapsUrl maps are used to map hosts and urls to backend services. The url maps hold two types of objects, host rules and path matchers. Each host rule can have multiple path matchers. Each request is matched against the host rule and then the path matchers for the host rule that matches. When creating a url-maps object you specify the default backend service that is used when no host rules match.gcloud compute url-maps create my-url-map --default-service my-http-backend-serviceIf you have only one backend service then this one command is usually enough since all traffic can be sent via the default service. However if you have multiple backends you can set the up based on host or url. A host rule can have multiple path matchers but the host rule must have at least one path matcher so we create the path matcher and host rule at the same time.gcloud compute url-maps add-path-matcher my-url-map --path-matcher-name my-www-path-matcher --new-hosts &lt;a href="http://www.example.com"&gt;www.example.com&lt;/a&gt; --default-service my-http-backend-serviceYou can specify that requests with a different host go to a separate backend service as well.gcloud compute url-maps add-path-matcher my-url-map --path-matcher-name my-api-path-matcher --new-hosts api.example.com --default-service my-api-backend-serviceLike the url-maps itself you specify a default service if the host rule matches but no path rules match. You can also specify different backend services be used based on the path.gcloud compute url-maps add-path-matcher my-url-map --path-matcher-name my-path-matcher --new-hosts &lt;a href="http://www.example.com"&gt;www.example.com&lt;/a&gt; --path-rules=”/api=my-api-backend-service,/other=my-other-backend-service” --default-service my-http-backend-serviceIn the UI the URL maps, host rules, and path matchers are specified in the “Host and path rules” section.The first row contains the default service which is used when a request doesn’t match a host rule/path matcher combination. The other rows contain the host rule/path matchers.Target ProxiesTarget HTTP Proxies and Target HTTPS Proxies are objects that connect one or more forwarding rule to a URL map.Target Proxies terminate the connection to the user so you specify the SSL certificate to use when you are using HTTPS. SSL certificates are created like so:gcloud compute ssl-certificates create my-cert --certificate /path/to/cert.pm --private-key /path/to/key.pmYou can then use the certificate to create the HTTPS proxy.gcloud compute target-https-proxies create my-https-proxy --url-map my-url-map --ssl-certificate my-ssl-certificateYou still need to create one but at this point I felt that Target Proxies made things more complicated than it needs to be since you almost always use one forwarding rule per target proxy for HTTP load balancers.Forwarding RuleForwarding rules are final object we need to create. These are the objects that your are actually billed against. The Forwarding Rules map the IP address for your load balancer to the Target Proxy that will handle the requests. First we will need to create our IP address though. We will need a global, rather than regional, IP address for our HTTP load balancer.gcloud compute addresses create my-address --globalThen we can create our forwarding rule. Notice that we will need to put in the actual IP address that we just created rather than the IP address name. Not also that you can only put a single port as the — port-range option and that we need to add the — global option.gcloud compute forwarding-rules create my-https-forwarding-rule --global --address 123.123.123.123 --ip-protocol TCP --port-range 443 --target-https-proxy my-https-proxyMany applications will want to redirect users that access http://www.example.com/ to https://www.example.com/. This is a pretty common use case that is not supported by the load balancer. You need to create a totally separate Target HTTP Proxy and Forwarding Rule for HTTP. You essentially need to have two load balancers to handle the traffic, and then actually redirect users in your application.Notice that we put the same IP address in for the HTTP Forwarding Rule. This makes is so that we can listen on port 80 and on port 443 at our IP address.gcloud compute target-http-proxies create my-http-proxy --url-map my-url-map gcloud compute forwarding-rules create my-http-forwarding-rule --global --address 123.123.123.123 --port-range 80 --target-http-proxy my-http-proxyNow that you’ve created a forwarding rule, it will show up in the “Load balancing” section of the developers console.The Advanced ViewThere is also an “Advanced View” that allows you to view the objects in a format that is much closer to the CLI counterparts. There are tabs for each of the major objects as well as a couple for the network load balancers.The objects that make up the HTTP(S) Load Balancer and the commands that you need to run to set it up on GCP are not totally obvious given how you create a in the UI. But hopefully this post has shed some light on how they map together. Be sure to also check out the HTTP Load Balancer documentation it has lots more info and guides like how to do some more complex setups like cross-region load balancing and content based load balancing.Google Cloud Platform HTTP Load Balancers Explained via the CLI was originally published in Google Cloud - Community on Medium, where people are continuing the conversation by highlighting and responding to this story.

== Article 2
* Title: 'Deploying Go Servers with Kubernetes on Container Engine'
* Author: 'Ian Lewis'
* URL: 'https://medium.com/google-cloud/deploying-go-servers-with-kubernetes-on-container-engine-3fee717a7e2a?source=rss-8660bca0444d------2'
* PublicationDate: 'Thu, 16 Jul 2015 05:07:27 GMT'
* Categories: 

Note: Cross posted on my blog.I was trying to get a Go app running on Container Engine and couldn’t quitefind what I was looking for. There are guides out there about how to use Go and Docker, and how to use Kubernetes but but not many about Go apps and Container Engine. I also found it easy to deploy apps but most guides lacked information on best practices for how to maintain apps through regular upgrades so I decided to research it and write a post about it myself.Be sure to check out the Container Engine documentation for details about the concepts and commands used.This post is a continuation of the Deploying Go servers withDocker article on the Go blog. Make sure you run through building the Docker image.Pushing the Docker Image to Google Container RegistryYou will need the gcloud tool so make sure you have the Google CloudSDK installed. Next you’ll need to create a project on the Google DevelopersConsole. Make note of the project id.Set up your gcloud tool with the right config. Replace &lt;project-id&gt; belowwith your project id. Replace &lt;zone&gt; with the zone of your choosing:$ gcloud config set project &lt;project-id&gt;$ gcloud config set compute/zone &lt;zone&gt;Once you have that done you will need to tag theimage using docker.$ docker tag outyet gcr.io/&lt;project-id&gt;/outyet:v1This will set the repository and tag it with the version ‘v1’. Next push theimage to the registry. You may get warnings about installing the `preview`components. Just say ‘yes’ to install them when asked.$ gcloud preview docker push gcr.io/&lt;project-id&gt;/outyet:v1Kubernetes ConfigurationWe will create a replication controller and service for our app.The replication controller configures how our app will be run and maintained in Kubernetes and the service allows our containers to be accessed as one logical service/app. Create a outyet-rc.yml file with the contents below. We will use the new v1 version of the API:kind: ReplicationControllerapiVersion: v1metadata:name: outyet-v1spec:  replicas: 3  selector:    name: outyet    version: “1”  template:  metadata:    labels:      name: outyet      version: “1”  spec:    containers:      — image: gcr.io/&lt;project-id&gt;/outyet:v1        name: outyet        ports:          — containerPort: 8080            hostPort: 8080            protocol: TCPNext we’ll create a service for our app. Create an `outyet-service.yml` withthe contents below:kind: ServiceapiVersion: v1metadata:  name: outyet  labels:    name: outyetspec:  ports:    — port: 80      targetPort: 8080      protocol: TCP  selector:    name: outyet  type: LoadBalancerDeploy the Container Engine ClusterNext we’ll deploy our container engine cluster. We’ll use the gcloud tool again. You may getwarnings about installing the `alpha` components. Just say ‘yes’ to install them when asked.$ gcloud alpha container clusters create outyet$ gcloud config set container/cluster outyetCreate the Replication ControllerAfter the cluster is created we can deploy the app. First we will create the replication controllers:$ gcloud alpha container kubectl create -f outyet-rc.ymlIt will take a few minutes for the pods to come up. You can see if the pods areready using the following command:$ gcloud alpha container kubectl get podsThe pods will say their state is `Pending` at first but will change toRunning when they are ready.Create the ServiceCreate the service with the following command.$ gcloud alpha container kubectl create -f outyet-service.ymlAfter the service is created we can see that it is created by viewing theoutput of this command:$ gcloud alpha container kubectl get servicesThe service uses the LoadBalancer feature of Container Engine to set up anetwork loadbalancer to our service. We can get the external IP of the service using the following command:$ gcloud compute forwarding-rules listThis will show the IP address of our service. Make note of the IP address.Finally we can create a firewall rule to allow access to our nodes:$ gcloud compute firewall-rules create outyet-http — allow tcp:80 — target-tags k8s-outyet-nodeNow we can view the app at http://&lt;IP Address&gt;/Upgrading the AppGo 1.4 is already out yet so app isn’t really exciting. Let’s update it so itchecks for Go 1.5. Lets override the CMD for the Dockerfile so it looks like this:FROM golang:onbuildCMD [“go-wrapper”, “run”, “-version=1.5”]EXPOSE 8080Next we will build, tag and push the updated docker image:$ docker build -t outyet .$ docker tag outyet gcr.io/&lt;project-id&gt;/outyet:v2$ gcloud preview docker push gcr.io/&lt;project-id&gt;/outyet:v2Next lets update all the places it says v1 in our outyet-rc.yml and change it to v2.kind: ReplicationControllerapiVersion: v1metadata:  name: outyet-v2spec:  replicas: 3  selector:    name: outyet    version: “2”  template:    metadata:      labels:        name: outyet        version: “2”    spec:      containers:        — image: gcr.io/&lt;project-id&gt;/outyet:v2          name: outyet          ports:            — containerPort: 8080              hostPort: 8080              protocol: TCPNext do a rolling update of our replication controller outyet-v1 to our newoutyet-v2:$ gcloud alpha container kubectl rollingupdate outyet-v1 -f outyet-rc.yml — update-period=10sThis should take about 30 seconds to run as we have 3 replicas and we’ve setthe update period as 10 seconds per replica.After that runs we can refresh our app again to see if Go 1.5 is out yet :)CleanupMake sure you delete your cluster so you don’t get charged too much money :)$ gcloud alpha container clusters delete outyetConclusionI really think containers are the way everyone will be developing apps in the future so hopefully that gave you an idea of how you can deploy a Go app and upgrade it using Container Engine. As a next step try out some of the many example apps available in the Kubernetes repo.Deploying Go Servers with Kubernetes on Container Engine was originally published in Google Cloud - Community on Medium, where people are continuing the conversation by highlighting and responding to this story.

== Article 3
* Title: 'Learning a Language as Muscle Memory'
* Author: 'Ian Lewis'
* URL: 'https://medium.com/@IanMLewis/learning-a-language-as-muscle-memory-16332f7c7666?source=rss-8660bca0444d------2'
* PublicationDate: 'Sun, 02 Jun 2013 14:57:19 GMT'
* Categories: 

I learned a lot from learning a second language. I started learning Japanese on my own and moved to Japan several years ago. I now work at a Japanese company where I spend most of my day speaking and writing Japanese.Most people think about learning a second language as a kind of rote learning. You memorize the vocabulary and grammar of a language and when the time comes to use it, you recall the vocabulary and grammar from your memory and use what you remembered to form a coherent thought or sentence. You do this in the same way to deconstruct things that other people say. Many language learning methods focus on this aspect of learning a language. Spaced Repetition is one of them and is an extremely good way of remembering vocabulary and facts.However, after interacting with many people living in Japan and attempting to learn the language, I felt that too many people focus on this area too much. Their knowledge of the language constructs, vocabulary and culture sometimes exceeds my own, but their fluency in conversation leaves something to be desired. How is that?I’ve  come to believe that learning a language is as much about muscle memory as about rote learning. Speaking a language is a real time activity. You need to be able to respond to a query, ideally, in about a second, and absolutely within a few seconds. Getting that kind of speed requires practice. You need to be able to understand commonly used phrases quickly, and react properly when you don’t know how to respond. The only way to really get better at conversation is to talk to people. The more the better.
