<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:cc="http://cyber.law.harvard.edu/rss/creativeCommonsRssModule.html">
    <channel>
        <title><![CDATA[Stories by Christoph Stanger on Medium]]></title>
        <description><![CDATA[Stories by Christoph Stanger on Medium]]></description>
        <link>https://medium.com/@ch.stanger?source=rss-213298b72369------2</link>
        <image>
            <url>https://cdn-images-1.medium.com/fit/c/150/150/1*sE3KBpibrUQp8BrGL87SYA.jpeg</url>
            <title>Stories by Christoph Stanger on Medium</title>
            <link>https://medium.com/@ch.stanger?source=rss-213298b72369------2</link>
        </image>
        <generator>Medium</generator>
        <lastBuildDate>Thu, 04 Jul 2024 15:32:01 GMT</lastBuildDate>
        <atom:link href="https://medium.com/@ch.stanger/feed" rel="self" type="application/rss+xml"/>
        <webMaster><![CDATA[yourfriends@medium.com]]></webMaster>
        <atom:link href="http://medium.superfeedr.com" rel="hub"/>
        <item>
            <title><![CDATA[An exploratory flight through your Serverless Architecture]]></title>
            <link>https://medium.com/@ch.stanger/an-exploratory-flight-through-your-serverless-architecture-d2d7b7128f2e?source=rss-213298b72369------2</link>
            <guid isPermaLink="false">https://medium.com/p/d2d7b7128f2e</guid>
            <category><![CDATA[serverless-architecture]]></category>
            <category><![CDATA[software-architecture]]></category>
            <category><![CDATA[openwhisk]]></category>
            <category><![CDATA[observability]]></category>
            <category><![CDATA[function-as-a-service]]></category>
            <dc:creator><![CDATA[Christoph Stanger]]></dc:creator>
            <pubDate>Sun, 30 Aug 2020 17:40:50 GMT</pubDate>
            <atom:updated>2020-08-31T08:06:44.238Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="Obervability of Serverless Applications‚Ää‚Äî‚Ääan OWVIS Demo" src="https://cdn-images-1.medium.com/max/1024/1*kupMo6LWpvJc_CidnoHslQ.png" /><figcaption>An <a href="https://github.com/cstanger/openwhisk-visualizer">OpenWhisk-Visualizer</a> preview to visualize Serverless Architectures.</figcaption></figure><p>Managing a serverless application design can be tedious due to the high amount of parallel running serverless functions and their composition. Many serverless applications are built in an ad-hoc and incremental way, whereby most teams perform little to no regular assessment of their FaaS implementations and the runtime characteristics. Inconsistency issues are slowly sneaking into the architecture.</p><p>While having such issues for an application deployed on OpenWhisk, I took a <strong>novel approach and created the </strong><a href="https://github.com/cstanger/openwhisk-visualizer"><strong>OpenWhisk-Visualizer (OWVIS)</strong></a><strong>.</strong> It allows teams to explore the architecture from a birds-eye perspective of a 3D-Map and helps to identify potential improvements.</p><p>With this post I want to inspire you to also take an exploratory flight through your serverless system for better architecture discussions and decisions.</p><blockquote>Within the last year I have been able to study the topic intensively from both the academic side (as part of <a href="https://github.com/cstanger/openwhisk-visualizer">my master‚Äôs thesis</a>) and from the application-oriented side as a developer at <a href="http://Maibornwolff.de">Maibornwolff</a>.</blockquote><blockquote>The entire concept of OWVIS is based on previously elaborated content regarding architecture visualization and s<a href="https://medium.com/@ch.stanger/serverless-architectures-ca5df80691c">erverless architecture properties</a> as well as <a href="https://medium.com/@ch.stanger/an-system-introduction-into-apache-openwhisk-74a7e07bf3ee">OpenWhisk and its runtime data extraction</a>.</blockquote><h3>Why? Why would you need it?¬†ü§∑üèΩ‚Äç‚ôÇÔ∏è</h3><p>In practice, many serverless applications are built in an ad-hoc and incremental way. Developers possess a modest amount of knowledge and perform little to no regular assessment of cloud function implementations and runtime characteristics. Moreover, it is recognized that components within an serverless architecture built upon serverless services are likely to become smaller and also more short-lived. I have discussed this in a previous article about s<a href="https://medium.com/@ch.stanger/serverless-architectures-ca5df80691c">erverless architectures</a>.</p><p>As a consequence, managing a serverless application design can be tedious due to the high amount of parallel running serverless functions and their composition. Inconsistency creeps into functional artifacts and the architecture, resulting in subtle variations in performance and scalability of function executions.</p><p><strong>A real-time insight into the deployed serverless architecture provides tremendous benefits. This is particularly true, if you are aiming for performance and cost-saving improvements.</strong></p><p>Therfore, OWVIS should provide a basis for discussion within the entire development team in order to improve and further develop the current architecture.</p><h3>What exactly is the OpenWhisk Visualizer (OWVIS)?</h3><p>It is a software to visualize FaaS architectures deployed on OpenWhisk only based on the platformÀãs runtime data. It should primarily address the demand for better FaaS development and observability tooling, as strongly expressed in the literature as well as in practice.</p><blockquote>The source code is publicly available at <br><a href="https://github.com/cstanger/openwhisk-visualizer">https://github.com/cstanger/openwhisk-visualizer</a><br>and a live demo is reachable at<br><a href="https://owvis.cstanger.at">https://owvis.cstanger.at</a></blockquote><p>The tool is easy to integrate and is also usable as a pure user of the FaaS platform, without any platform backend privileges. Therefore, no changes to the FaaS platform itself is necessary.</p><p>In order to promote discussions around the architecture as best as possible, <strong>the visualization is interactive and emphasize various and unknown aspects of the architecture.</strong> A city metaphor is used for the visualization and a three-dimensional map of buildings gets rendered. <strong>Each building represents a single function.</strong></p><p><strong><em>- </em></strong><em>The height, <br></em><strong><em>- </em></strong><em>the size of the base area and <br></em><strong><em>- </em></strong><em>the color </em><br>of the buildings are used to picture different metrics of those entities. Directed edges between buildings can further display dependencies.</p><figure><img alt="An OpenWhisk-Visualizer preview to visualize Serverless Architectures." src="https://cdn-images-1.medium.com/max/1024/1*2J0mcda0qb6rhnW9doq1Xg.png" /><figcaption>An OWVIS demo preview to visualize Serverless Architectures.</figcaption></figure><h3>What exactly are concrete use¬†cases?</h3><p>Therefore, OWVIS provides a variety of predefined visualization templates, called scenarios, to describe different aspects of a FaaS architecture.</p><h4><em>OpenWhisk Overview</em></h4><p>First of all, an overview about the deployed architecture is necessary, right?The scenario <em>OpenWhisk Overview</em> offers a very first impression and allows stakeholders to get an overview of what is deployed. Based on the extracted runtime data, the visualization presents each function as a 3D building¬†block.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*pJFBpqrENFM-jVdjeqmeNg.png" /><figcaption>Overview Scenario</figcaption></figure><p>The size of the base area describes the allocated memory of a function. The subplatforms group functions and represent OpenWhisk namespaces.</p><p>The height puts the average execution duration in relation to each other and the color scheme indicates the total costs. Which is naively calculated by multiplying the average duration, with the allocated memory and with the amount of¬†calls.</p><p>Moreover, incoming and outgoing edges between function buildings show execution dependencies. They indicate that the linked functions are either part of an explicit sequence or that one function was called manually during the execution of another function, with respect to the direction of the¬†edge.</p><h4>OpenWhisk RED</h4><figure><img alt="OWVIS: RED Scenario" src="https://cdn-images-1.medium.com/max/1024/1*S4UARur4Jj0AGXYkf-INsQ.png" /><figcaption>OWVIS: RED¬†Scenario</figcaption></figure><p>Another scenario, called <strong><em>OpenWhisk RED</em></strong>, is based on the RED method for monitoring microservices. The acronym stands for<strong> r</strong>ate, <strong>e</strong>rror and <strong>d</strong>uration and provides a basis for consistent monitoring, especially for developers who may not be familiar with the deployed microservice architecture. According to this concept, the height of the functional buildings shows the number of total activations (rate) and the floor area the average execution duration (duration). The error dimension is embedded in the color scheme and measured in terms of the total success¬†rate.</p><blockquote>Both use cases screenshots demonstrate and verify OWVIS‚Äôs capabilities to provide a first overview of a yet unknown FaaS architecture while providing a common foundation and understanding for architecture decisions within a development team.</blockquote><p>But besides that, OWVIS has also visualization scenarios implmentet to <strong>promote architectural improvements</strong> by targeting specific FaaS architecture patterns. For example <em>Oversize Functions.</em></p><h4>Oversize Functions</h4><p>Oversizing of functions is an often observed pattern in FaaS architectures. Too much and not required memory gets allocated in order to increase CPU performance. However, this can result in unintentionally high costs, because they are based on the required execution duration and the provided amount of memory (like with AWS Lamdba or Google Functions).</p><p>It is therefore important for architects and developers to keep an eye on the oversizing of individual functions and continuously assess the impact on costs. In order to do this, it is valuable to put the over-provisioned memory in relation to the execution duration, like formalized in the following:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*n4bm5XzgkFTDykIBkpNVXA.png" /></figure><p>The metric <em>oversizedCostsAverage</em> is also available in OWVIS and is applied to the visualization scenario named <em>Function Oversizing</em> as the color scheme. The function buildings take the amount of unused memory in megabytes (MB) as the height and the average execution duration as the size of the base¬†area.</p><figure><img alt="OWVIS: Function Oversizing" src="https://cdn-images-1.medium.com/max/1024/1*hNQXSRaDVcNnHUZ7lJb0GA.png" /><figcaption>OWVIS: <em>Function Oversizing</em></figcaption></figure><p>The illustration clearly indicates functions that are considerably oversized and have long running durations, as for example the <em>DemoFunctions/getInput</em> function. The height shows an average unused memory of 492 MB. Only <em>MailForm/form</em> and <em>DemoFunctions/timeoutError</em> face comparable oversizing. Nevertheless, due to the overall size and coloring, it becomes evident that the function <em>DemoFunctions/timeoutError</em> causes the highest oversized costs due to its large average execution duration.</p><p>Initial indicators of potential for reducing costs caused by oversizing are therefore shown, but these must be assessed in detail with regard to the function domain context and expected extreme memory or duration¬†values.</p><h4><em>Read-heavy reporting engine (Caching)</em></h4><p>For functions with read-intense workloads, the <em>read-heavy reporting engine </em>pattern suggests to use a cache for frequently used execution parameters. Instead of computing the function output each time, the result should be cached and associated with the corresponding function input. This allows for effective reduction of execution duration, hence¬†costs.</p><p>However, this is only applicable if the function is deterministic in its behavior.</p><p><strong>By evaluating the determinism of each function, OWVIS helps to assess which components of the FaaS architecture can benefit from introducing the <em>read-heavy reporting engine</em> pattern</strong>. The scenario <em>caching suggestions</em> represents the proportion of deterministic inputs of each function using a color scheme. If a function is deterministic, the height of the graphical representation further highlights the potential for reducing the execution time. The following equation is used to calculate the necessary metric based on the available runtime¬†data:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*qiMvRLKAdyVz6yQ0XcZP9w.png" /></figure><p>The screenshoot below applies the scenario to the deployed evaluation applications. Especially the mathematical demo functions are shown by OWVIS as suitable candidates for caching. The comparison between the functions <em>Math/primeNumberCached</em> and <em>Math/primeNumber</em>, where one is with and one without naive in-memory caching, shows that the potential for improvement is correctly recognized.</p><figure><img alt="OWVIS: caching suggestions" src="https://cdn-images-1.medium.com/max/1024/1*3RTDrs0a_O2tpX2OO9v0ug.png" /><figcaption><em>OWVIS: caching suggestions</em></figcaption></figure><p>However, it must be mentioned, that the property of a function to be deterministic cannot be uniquely determined from runtime data, as not every conceivable input is available. The metric used in OWVIS therefore only provides an indication and must be evaluated in detail with regard to the function‚Äôs business¬†domain.</p><h3>How is OWVIS build¬†up?</h3><p>The whole application has a modular structure and all the services are packed into docker containers in order to ease its deployment and portability. The application is designed to support multiple configuration and deployment options.</p><p>Firstly, the application is capable of running locally as an interactive Node.js process in a terminal. Necessary configurations, such as OpenWhisk credentials or the OpenWhisk host address, need to be set as environment variables.</p><p>But as a fully containerized application, <em>Docker-Compose</em> is convenient to use in order to start and configure all necessary services. The therefore required docker-compose.yaml file is included in the repository of the OWVIS¬†project.</p><p>Thirdly, since Kubernetes is one of the most important deployment options for the OpenWhisk platform, OWVIS is also intended for easy deployment there. <strong>A <em>HELM chart</em>, which is available in the repository, allows to deploy and use OWVIS with a single¬†command.</strong></p><p>The diagram below depicts a holistic overview of all services as well as inter-system dependencies. It also describes the components of which the application consists¬†of.</p><figure><img alt="OWVIS System Architecture" src="https://cdn-images-1.medium.com/max/1024/1*iC00hkE3rgqe3opa9C3Vgw.png" /><figcaption>OWVIS System Architecture</figcaption></figure><p>The green area represents an OpenWhisk namespace within a cluster. It includes relevant components of the OpenWhisk FaaS platform, as described in detail <a href="https://medium.com/@ch.stanger/an-system-introduction-into-apache-openwhisk-74a7e07bf3ee">in my previous blog¬†post</a>.</p><p>The orange box refers to an OpenWhisk Visualizer namespace with the four docker containers OWVIS itselfe, MariaDB, <a href="https://github.com/MaibornWolff/codecharta">CodeCharta</a> (an amazing project from MaibornWolff) and NginX. The arrows between both namespaces show the possible channels OWVIS is able to use in order to fetch the runtime data. The black arrow represents the standard process via the REST API and the red arrows indicate the possibility of additional request paths that can only be used as OpenWhisk provider because they require access to the internal OpenWhisk backend services.</p><h3>Limitations</h3><p>Although the given implementation of <strong><em>OWVIS</em></strong> is beyond a prototype, the tool still faces some limitations that need to be mentioned.</p><p>First of all, aggregation and sampling methods need to be applied manually within the <em>OWVIS</em> database. Currently, no such mechanisms are implemented that aggregate and filter out runtime data in <em>OWVIS</em> to free up storage space within the database over time. This is also necessary in order to apply a time filter on the visualized metrics.</p><p>Secondly, due to OpenWhisk‚Äôs API limitations of responding with a maximum of 200 activation records per request, it requires a large number of API calls to pull all runtime data from OpenWhisk when the FaaS platform is under huge load. This also affects <em>OWVIS</em> if it is configured with user privileges and therefore depends on the OpenWhisk API. Long computation cycles and therefore latency in updating the visualization can be observed with an increasing amount of new activation records. However, this was not detected when using a provider configuration. <a href="https://github.com/cstanger/openwhisk-visualizer">For more details, look into the benchmarking part within the GIT¬†Repo</a>.</p><p>Additionally, it needs to be considered that the metrics and visualizations in <em>OWVIS</em> do not include any considerations for either the business domain of the function nor a static code analysis. Therefore, every suggestion for improvement must be aligned and interpreted with the actual purpose and implementation of a function.</p><h3>Conclusionüìö</h3><p>OWVIS aims to support software architects in dealing with the novel serverless paradigm and its increasing system complexity by deriving properties of Function as aService architectures.</p><p>The major contribution of this work includes the implementation ofthe <strong>OpenWhisk-Visualizer (OWVIS)</strong>, which visualizes a Function as a Service architecture in terms of its runtime data and identifies opportunities for improvement.</p><p>Based on the evaluation it can be concluded, that OWVIS is capable of visualizing various aspects of an applied Function as a Service architecture and guiding towards cost improvement considering common serverless patterns. It therefore successfully contributes to enhance serverless development tooling.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=d2d7b7128f2e" width="1" height="1" alt="">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[An system introduction into Apache OpenWhisk]]></title>
            <link>https://medium.com/@ch.stanger/an-system-introduction-into-apache-openwhisk-74a7e07bf3ee?source=rss-213298b72369------2</link>
            <guid isPermaLink="false">https://medium.com/p/74a7e07bf3ee</guid>
            <category><![CDATA[function-as-a-service]]></category>
            <category><![CDATA[platform-design]]></category>
            <category><![CDATA[openwhisk]]></category>
            <category><![CDATA[function-instrumentation]]></category>
            <dc:creator><![CDATA[Christoph Stanger]]></dc:creator>
            <pubDate>Wed, 05 Aug 2020 13:54:58 GMT</pubDate>
            <atom:updated>2020-08-17T15:37:17.221Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="Apache OpenWhisk Logo" src="https://cdn-images-1.medium.com/max/936/1*L7028WzHDlwgECHH6sGm6Q.png" /></figure><p>Serverless is getting popular and the demand for quickly deploying code without worring about the infrastructure is increasing.</p><p>As the term <em>serverless</em> is quite missleading, it is worth to explicitly remark the necessity for servers and operation engineers to run a serverless platform. The term rather refers to a separation of concerns by identifying two primary serverless personas. On the one hand te provider deploys the serverless platform, managesunderlying hardware and its costs, even when idle. Whereas the developer, also referred to as user in the following, on the other hand, can solely focus on writing code representing the business logic and no longer needs to spend time and resources on server provisioning, maintenance, scaling or capacity planning. A self-hosted serverless platform can still be considered serverless, as one department can act as the provider and another as the developer.</p><p>And multiple such self-hostable serverless platfroms are out there.<strong> One of them is the open-source project Apache OpenWhisk, </strong>which I would like to explain in more technical detail in this article. Likewise, I would like to point out the available runtime data, which are extremely valuable for any operator and enable better observability.</p><p>Apache OpenWhisk is a serverless FaaS platform that executes functions in response to events. It was initially developed by IBM and was open-sourced under the Apache License (Version 2.0) in 2016. It still builds the core technology behind <a href="https://cloud.ibm.com/functions/">IBM‚Äôs cloud function</a> offerings as well as the <a href="https://www.adobe.io/apis/experienceplatform/runtime">Adobe I/O Runtime</a> and can therefore truly call itself production-ready. The<a href="https://github.com/apache/openwhisk"> GitHub project</a> counts 177 contributors, over 4.700 stars and 931 forks [as of June 4, 2020]. The main contribution still derives from the companies IBM, Red Hat and¬†Adobe.</p><p>The platform comes with a stable REST API-based interface supporting all capabilities of the system. Additionally, the OpenWhisk Command-line Interface (CLI) called <em>wsk</em>, which is implemented in the programming language Go, allows interacting with the platform and all its capabilities from a¬†client.</p><p>The structure and main functionalities are described from a developer perspective and are later referred to as the programming model. Additionally, the technical architecture and underlying technologies of Apache OpenWhisk are explained in detail in the following.</p><h3>Programming Model</h3><p>The platform‚Äôs event-driven programming model can be divided into five main internal entities, namely<strong> triggers, rules, actions, namespaces </strong>and <strong>packages</strong>. A trigger represents an event from various event sources and is linked by a rule to an action, which embodies functional logic. The following figure shows the interrelation of these entities.</p><figure><img alt="Apache OpenWhisk Programming Model description" src="https://cdn-images-1.medium.com/max/935/1*XnxTRjJNI8iqwnc1UtjtCQ.png" /><figcaption>OpenWhisk Programming model description</figcaption></figure><p>In more detail, <strong>triggers</strong> are named channels receiving events from internal or external sources. Such event sources generate events that either indicate changes in data or transmit data themselves. OpenWhisk can handle event sources of different types such as Message Queues, Databases, IoT device sensor data, Git Repositories or Slack channels. Manual activations of triggers are also possible using the CLI¬†<em>wsk</em>.</p><p>A <strong>rule</strong> represents a linkage between one trigger and one action, so that a trigger activation causes an action to be executed with the event as an input parameter. Multiple rules can be applied to both triggers and actions, resulting in a n:n relationship between them. Besides rules, a RESTfull API interface allows to invoke actions directly via HTTP¬†calls.</p><p>Furthermore, an <strong>action</strong> is a stateless function encapsulating the application logic which is getting executed when the action gets invoked. The described programming model allows a programming language agnostic event handling, which means that each action can be implemented in a different programming language. The Apache OpenWhisk project officially supports Go, Java, Node.js, PHP, Python, Ruby, Swift and¬†.Net. Interpreted programming languages such as Node.js, PHP or Python are typically used as they execute without a compilation step and are suitable for the highly responsive FaaS model. In addition, OpenWhisk has the ability to also run a Docker container as an action. That makes it possible to use any programming language with any kind of packages and binaries, as long as they are packaged as Docker containers. The only requirement for a function is to accept a dictionary of key-value pairs as input parameter, where the key is a string and the value is any valid JSON. The return value needs to be of the same datatype. The following sample action gives a proper sample action written in¬†Node.js.</p><figure><img alt="OpenWhisk Sample Action" src="https://cdn-images-1.medium.com/max/1024/1*ZF7unKLBXKGXA3N5MZN4AA.png" /><figcaption>A sample action written in¬†Node.js</figcaption></figure><p>Every time an action gets executed, a unique activation ID is assigned, gets associated with that specific event and an activation record is created. This activation record holds metadata like execution duration, output parameters and action properties (such as maximum execution duration, available memory and runtime environment).</p><p><strong>Namespaces </strong>and<strong> packages</strong> embody organizational entities. Triggers, rules, and actions belong to a namespace and actions can further be grouped into one package at a second level. A namespace describes a user‚Äôs property, whereas packages can hold metadata and default configurations for all grouped actions. The structure of a fully qualified name is therefore written as <em>/&lt;namespaceName&gt;[/&lt;packageName&gt;]/&lt;entityName&gt;</em> where the package name is optional.</p><p>Moreover, the OpenWhisk programming model allows for action compositions called a <strong>sequence</strong>. It composes multiple actions, even from different programming languages, in order to create a static activation pipeline where the output of one action becomes the input of the following action. The output of the last action will get the final result of the sequence. Likewise, the concept of so-called <strong>conductions</strong> can combine multiple actions during runtime and allows to invoke a dynamic series of actions. It is important to mention, that both compositions methods invoke the involved actions autonomously so that separate activations are generated and¬†logged.</p><h3>Platform Architecture</h3><p>The internal architecture of Apache OpenWhisk consists of multiple, loosely coupled components packed in containers. Most of them build on top of well established, cloud-native open-source technologies such as Docker, CouchDB, Kafka or NginX. The containerization enables multiple deployment options for installing and configuring the platform either locally or within a cloud infrastructure. Still, the recommended deployment option is using the open-source container orchestration platform Kubernetes. Other options include tools like Docker-Compose, Ansible, Vagrant or Mesos. All necessary components of the OpenWhisk platform architecture and their interaction are described in detail hereafter.</p><figure><img alt="Apache OpenWhisk Platform Architecture Overview" src="https://cdn-images-1.medium.com/max/900/1*NnctQFU0C2JgUlbjsJrwkg.png" /><figcaption>OpenWhisk Platform Architecture (overview)</figcaption></figure><h4>NginX</h4><p>The open-source NginX webserver technology is used as the user-facing entry point. It exposes the HTTP based, RESTful API of the system. As a reverse proxy it mainly handles the SSL termination and the request routing including also those from the CLI <em>wsk</em>. It mainly forwards requests to the controller.</p><h4>Controller</h4><p>The controller embodies the central gatekeeper of the system as it has implemented the actual OpenWhisk API (written in Scala) and performs authentication and authorization tasks. CRUD operations for OpenWhisk entities and also function calls get verified and orchestrated by the controller. It also acts like a load balancer to all active actions or eventually decides to span up a new execution instance called invoker. For this task the controller consults a database, by default a¬†CouchDB.</p><h4>CouchDB</h4><p>An instance of the NoSQL database Apache CouchDB handles and maintains the state of the system. All data regarding user credentials, triggers, rules, functions and activation metadata are stored at this place. The CouchDB is therefore mainly accessed by the controller to perform authentication tasks and by the invoker to get an action‚Äôs source code and to write back the activation record.</p><h4>Invoker</h4><p>The invoker components‚Äô job is to run a function in a multi-tenant but isolated way. Docker is used to provide these execution environments. For a received execution instruction an invoker fetches the associated source code from the CouchDB and injects it into a Docker container with the necessary language runtime. The code then gets executed using the parameters passed from the activation. Once the execution is finished, the result and other execution metadata are pushed back in the CouchDB for future retrievals and the container gets destroyed by the invoker when idle. Multiple performance optimizations are done at this point to reduce provisioning overhead and keep response times as low as possible. It is called a cold start when the invoker needs to go through this whole process. But the invoker can also use already running runtime containers (prewarm containers) or reuse previously injected containers by not destroying them right after execution. Multiple invokers are used in parallel to handle a rapid scale by considering the actual request rate of an¬†action.</p><h4>Kafka</h4><p>Apache Kafka is used to manage resilient communication between the internal components and to achieve low coupling while providing high scalability possibilities. As a publish and subscribe (PubSub) messaging service, Kafka buffers messages with event information from the controller and sends a confirmation when a message was delivered to the invoker successfully. The controller can then respond to a user request with the associated activation ID. This ID can later be used to retrieve activation metadata and the return value. The sequence diagram in the following visualizes this asynchronous response handling.</p><figure><img alt="OpenWhisk Action Processing Sequence / Workflow" src="https://cdn-images-1.medium.com/max/1024/1*XUj8J4G7KhXhT12jbL56nA.png" /><figcaption>OpenWhisk Action Processing sequence</figcaption></figure><h3>Runtime Data of OpenWhisk</h3><p>Apache OpenWhisk provides multiple ways to get runtime data out of the system. However, it must be considered that some methods are limited to the platform operator. But as observed in the following, the information is congruent or can be made accessible to platform users by service providers.</p><h4>Activation Records</h4><p>As described, OpenWhisk creates a unique activation record for each function call. All the platform‚Äôs runtime data for an individual activation is included in that record and additionally the function output, a dictionary of key-value pairs, is attached. The invoker component is then responsible for storing the activation record in the CouchDB database, where it stays available for later reference.</p><p>The example below further reveals the structure of such an activation record and all its properties. In line 1 the CLI tool wsk is used to invoke the action <em>greeting</em> in the namespace <em>guest</em> and package <em>sampleFn</em>. The function code is equal to above listed action. The returned activation ID <em>3c4734bc69fc42b48734bc69fc72b447</em> allows to retrieve the respective activation record (starting at line 6), including all runtime data the platform OpenWhisk is aware of. That includes the execution duration (line 14), status code (line 15 and line 18) and the result dictionary (line 20 to¬†22).</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*N9a3qM5vOXaM8AsQ0cry2Q.png" /><figcaption>OpenWhisk Activation Record¬†Example</figcaption></figure><p>If the annotations array (starting at line 27) includes an object with a key property equal to <em>initTime</em>, the function execution was based on a cold start and the respective value indicates the time in milliseconds that it takes to deploy the runtime environment. Otherwise, it indicates a warm start, therefore an already existing function instance was used for execution. In the example, the activation was a <em>cold start</em> and the provision of the Node.js runtime container including loading of all dependencies took <em>141 milliseconds</em>. The <em>initTime</em> is also included within the total execution duration of <em>159 milliseconds</em> (line 6) of the execution.</p><p>The annotation array also contains data about the limitation settings of the execution environment starting at line 45, as well as information about the <em>runtime type</em> (line 37) and if the execution ran into a <em>timeout</em> at line 41. Moreover, the <em>waitTime</em> determines the time delay with which an execution request remains in the queue until an invoker is available to process¬†it.</p><p>Moreover, the activation records include an array of <em>logs</em>. Data, written to the standard output stream (Stdout) or standard error stream (Stderr) by the function process is handled by the invoker. For each output a log line is attached to the logs array, including a timestamp and the output stream message. As declared in line 7 of the example action above, the function logs an object with the given input parameters with the <em>conosle.log() </em>method. The example activation shows that output in line¬†25.</p><p>An activation record may also include a <em>cause</em> field. Only if the activation was triggered by another function as part of a sequence or a conduction, this field exists and refers to the preceding activation ID. Additionally a <em>causedBy</em> object in the annotation array would then indicate whether the execution was part of a sequence or a conduction.</p><blockquote>For developers and architects, the data provided within an activation record is of great value and often essential for the whole development process as well as for operations. It provides a basic foundation for correct debugging and monitoring of applications deployed on OpenWhisk. Therefore, the platform provides a variety of access mechanisms to the¬†data.</blockquote><p>All the platforms capabilities are available through a REST API. Hence also the polling of activation records is possible by using the following endpoint with a GET¬†method:</p><p><a href="https://{APIHOST}/api/v1/namespaces/_/activations/{ACTIVATION_ID}"><em>https://{APIHOST}/api/v1/namespaces/_/activations/{ACTIVATION_ID}</em></a></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*1IydHLPQcoEORhfgH2pSxA.png" /><figcaption>Activation Record Retrieval of OpenWhisk through the REST¬†API</figcaption></figure><p>Tools like the OpenWhisk CLI <em>wsk</em>, the OpenWhisk Client for JavaScript and the OpenWhisk Go client API library are interfaces to the REST¬†API.</p><p>Because a CouchDB component acts as a repository for the activation records in the system, direct database access is another option, but <em>only if you are operating the platform and have access rights to the backend systems.</em> The <em>\_activations</em> database keeps all activation record documents and is accessible through the CouchDB query¬†syntax.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*BNZEEcYBzg3JjxQOOvYWhQ.png" /><figcaption>Activation Record Retrieval of OpenWhisk through direct DB¬†access</figcaption></figure><h4>Not enough¬†data?</h4><p>The available <strong>default runtime data in OpenWhisk</strong>, as described above, might be sufficient for basic monitoring purposes during operations, for example to alert on a defined execution error rate, or to detect outliers in execution duration. However, further investigation and debugging is already limited by the amount of available information. You will likely miss important metrics within the activation record. The allocated memory during execution or the number of different input values are examples of unavailable metrics with high value within the development process.</p><p>But in the role of a platform user without back-end access, the options for customizing the FaaS platform are rare. Nevertheless, function instrumentation is in the scope of a platform user and might be an option to enrich the runtime¬†data.</p><p>Check out my <a href="https://github.com/cstanger/openwhisk-instrumentation"><strong>OpenWhisk instrumentation framwork for Node.js</strong></a> action to enrich the available data! With a special attention to the impact on performance, the framework was evaluated and multiple configurations are available.</p><p>Get started really quick by only installing the npm package, import the module and wrapping the exported function.</p><pre>$ npm install openwhisk-instrumentation --save</pre><p>The module can be implemented by just two lines of¬†code:</p><pre><strong>const { owInstrumentation, config } = require(&#39;openwhisk-instrumentation&#39;);</strong><br><br>const main = (params) =&gt; {<br>  const name = params.name || &#39;stranger&#39;;<br>  return { msg: `Hello World, ${name}!` };<br>};<br><br>module.exports.main = <strong>owInstrumentation(</strong>main<strong>)</strong>;</pre><p>By default, the collected metrics get logged to the¬†Stdout:</p><pre>&quot;2020-05-11T16:08:36.8207801Z   stdout: METRIC COLDSTART 0&quot;,<br>&quot;2020-05-11T16:08:36.8213629Z   stdout: METRIC INPUTHASH b849dca53a85606dd0fb247d0ad6130a6ee46da2&quot;,<br>&quot;2020-05-11T16:08:36.8217714Z   stdout: METRIC OUTPUTHASH a93451f69c7640073e02455f946b09047f32d1a3&quot;,<br>&quot;2020-05-11T16:08:36.8221925Z   stdout: METRIC CPUTIME_USER 193&quot;,<br>&quot;2020-05-11T16:08:36.8226241Z   stdout: METRIC CPUTIME_SYSTEM 31&quot;,<br>&quot;2020-05-11T16:08:36.8228241Z   stdout: METRIC MEMORY 31&quot;,</pre><p>I hope you could get some insights into Apache OpenWhisk and you understand the basic concept behind the platform. Be aware that the platform comes with even more helpful components.</p><p>OpenWhisk is straight forward to deploy. So get your hands a bit dirty and run your own self-hosted Function-as-a-Service platform with Apache OpenWhisk.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=74a7e07bf3ee" width="1" height="1" alt="">]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Serverless Architectures]]></title>
            <link>https://medium.com/@ch.stanger/serverless-architectures-ca5df80691c?source=rss-213298b72369------2</link>
            <guid isPermaLink="false">https://medium.com/p/ca5df80691c</guid>
            <category><![CDATA[serverless-architecture]]></category>
            <category><![CDATA[serverless-patterns]]></category>
            <category><![CDATA[function-as-a-service]]></category>
            <category><![CDATA[openwhisk]]></category>
            <category><![CDATA[serverless]]></category>
            <dc:creator><![CDATA[Christoph Stanger]]></dc:creator>
            <pubDate>Tue, 04 Aug 2020 16:13:49 GMT</pubDate>
            <atom:updated>2020-10-03T15:59:38.593Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*7zRVijKTzIQrWPydyO9vBg.jpeg" /></figure><p>The field of <strong>serverless (SLS)</strong> recently emerged as a new cloud computing paradigm, allowing to efficiently develop and deploy scalable applications without having to manage any underlying infrastructure. It is rapidly gaining momentum within the cloud industry and is even recognized to be the next fundamental evolution in <strong>cloud-native software development</strong>, as it further abstracts away hardware and operational concerns of cloud-based software engineering. Developers can focus on the business logic rather than worry about managing infrastructure resources.</p><p>In addition to these and other development benefits, practice and research show how this new paradigm has made software architects rethink application design and technical architectures. In this blog post, serverless architectures and their special features are presented and described. Several serverless architecture patterns outlined here should give you a first starting point for your concrete implementation.</p><blockquote>Within the last year I have been able to study the topic intensively from both the academic side (as part of <a href="https://github.com/cstanger/openwhisk-visualizer">my master‚Äôs thesis</a>) and from the application-oriented side as a developer at <a href="http://Maibornwolff.de">Maibornwolff</a>. In this blog post, I want to share and summarize gained insights about serverless architectures and their key properties.</blockquote><h3>Intro üí°</h3><p>The <a href="https://ieeexplore.ieee.org/document/875998">IEEE Recommended Practice for Architectural Description for Software-Intensive Systems</a> defines software architecture as¬†follows:</p><blockquote>Software architecture is the ‚Äú<em>[‚Ä¶] fundamental organization of a system embodied in its components, their relationships to each other, and to the environment, and the principles guiding its design and evolution</em>‚Äù</blockquote><p>It is recognized as a critical part of the software design process, as multiple architecture decisions and inherited tradeoffs directly affect future performance, quality, and maintainability. Missing or poor architecture is likely to result in slow and costly software and it will be expensive to add new features in the future. Therefore, software architecture is often the primary step towards designing a software¬†system.</p><p>This is (also) particularly true for cloud native software, which refers to applications that were developed especially to run within a cloud environment and to exploit the full advantage of cloud computing platforms and its services. Key aspects of such application architectures are the strong focus towards an open-source software stack and a microservice-based architecture. <em>A decomposition of a monolithic application into smaller, specialized, independent and event-driven microservices is recommended. It enables better scalability properties and advantages in aiming for reliability.</em></p><h3>Towards Nanoservices</h3><p>Hardly any other architectural pattern has received more attention in recent years than<strong> the concept of microservices.</strong> Instead of deploying a large software system in one piece (deployment monolith), it gets modularized into autonomous services. It gains its appeal also from its characteristic advantages when deployed in a cloud environment, such as <strong>independent development</strong> and <strong>deployment, technology freedom</strong> and the possibility of <strong>autonomous scaling </strong>for each service. The stated characteristics result primarily from the reduction of the service size and eliminating of hard dependencies among services. A reason that tempts to push this break down further. And this tempts us pushing this splitting of services further into even smaller¬†ones.</p><blockquote>In literature, a service that has been split to the extreme, where each service component only handles one particular operation for one specific business domain with minimal resource allocation, is also referred as a nanoservice.</blockquote><p>The term was particularly influenced by<a href="https://books.google.de/books?id=ikdmDwAAQBAJ"> Eberhard Wolff</a>¬†, who also adds that new technological approaches are needed to handle such nanoservices: If services become too fine-grained, the communication, coordination, scaling and infrastructure effort will rise and can have negative impact on the overall¬†system.</p><p><strong>Serverless technology can help to overcome this trade-off</strong> and can enable further downsizing of microservices. In fact, in order to be able to use function-as-a-service platforms efficiently, microservices even need to be broken down further to the level of functions and events. That is demonstrated schematically in the following figure.</p><figure><img alt="A comparison between Monolith, Microservice- and Serverless Architectures by development, coordination and platform effort" src="https://cdn-images-1.medium.com/max/1024/1*jU8A1ijIz_-YvBNeFY12ig.png" /><figcaption>Comparison between Monolith, Microservice- and Serverless Architectures</figcaption></figure><p>FaaS technology improves the shortcomings of a microservice model as the infrastructure and scaling overhead is deligated to the platform provider. Additionally, most FaaS platforms offer function composition functionalities. Thus, even the communication and coordination exertions between the functions are simplified. For example, the <a href="https://openwhisk.apache.org/documentation.html">OpenWhisk programming model </a>introduces sequences and conductions that take over most communication and coordination tasks.</p><p>Despite this, a consequence of the rising number of cohesive, fine-grained functions and their inter-dependencies is that the system complexity is further increasing. The upper comparison Figure is illustrating this kind of shift. <strong>A serverless architecture requires much more effort and toolings in dealing with this complexity.</strong> Especially to not lose the overview of a rapidly evolving¬†system.</p><blockquote>Another upcoming blog post will continue to address this issue‚Ää‚Äî‚Äästay¬†tuned!</blockquote><h3>Serverless Architecture Properties</h3><blockquote>An architecture which is mainly built upon functions hosted on a FaaS platform and complemented by various BaaS services such as databases, message queues, API gatways and storage options can be described as a serverless architecture.</blockquote><p>FaaS can either be used for enhancing current microservice architectures by providing ‚Äúglue‚Äù code between services. That means to use FaaS to connect multiple services and forward events or messages. It can also be used to efficiently replace seldom, event-based functionalities and is often referred to as a hybrid model in the literature. On the other hand, fully serverless architectures arise, where the whole application is built upon serverless functions to reap the full benefits of serverless and to eliminate concerns about the infrastructure.</p><h4>Event-driven</h4><p>Such architectures especially need to cope with the characteristics of FaaS like the event-driven and stateless property. FaaS is by definition <strong><em>event-driven </em></strong>and this property is therefore also inherited by serverless architectures. Architects should ( and need to) strongly promote this paradigm so that services produce, detect, consume, and respond to¬†events.</p><h4>Asynchronous function¬†calls</h4><p>Especially <strong><em>asynchronous function calls</em></strong> are well suited and preferred. The danger of hidden double billing is otherwise a common pitfall, as the requesting function would also be invoiced while it simply waits for a response. This is even more significant with cold starts eventually happening!</p><h4><strong>Fine service granularity</strong></h4><p>Another important consideration regarding cold starts is the <strong><em>service granularity</em>.</strong> The more individual FaaS functions exist in the system, the more cold starts begin to occur due to their individual life cycles. A trade-off argument compared to the previously discussed advantages of multiple granular services.</p><h4><strong>Stateless services</strong></h4><p>An essential characteristic of serverelss architectures is the implementation of <strong><em>stateless services</em></strong>.</p><p>FaaS functions have serious limitations to handle state that is required to be persistent. Any such state must be externalized from the service itself. That‚Äôs why functions within a serverless architecture typically make use of BaaS-like databases or network storage. This needs to be considered especially when it comes to¬†caching.</p><h4><strong>Pay for what you¬†use</strong></h4><p>An additional consideration in serverless architectures are <strong><em>operational costs</em></strong>. Firstly, the basis for operating costs incurred is fundamentally different compared to traditional cloud architectures. Instead of being billed for running VMs (independent from their utilization), each single function execution is billed by its duration in combination with its reserved memory independently (pay per use). Architectural considerations towards cost optimization therefore concern each component individually and in a more granular way within a serverless architecture. Thus, the factor of cost is present in every development decision.</p><h4><strong>No central¬†arbiter</strong></h4><p><a href="https://martinfowler.com/articles/serverless.html">Mike Roberts</a> introduces another important aspect. In serverless architectures there is <strong><em>no central arbiter of processes</em></strong>. ‚Äú<em>Instead we see a preference for choreography over orchestration, with each component playing a more architecturally aware role [‚Ä¶]</em>‚Äù, <a href="https://martinfowler.com/articles/serverless.html">he concludes</a>. More independent responsibility lies directly in the various services accordingly and thus also in the individual development teams.</p><p>However, additional <strong><em>limitations of common FaaS Platforms</em></strong> such as runtime duration restrictions or memory limits need to be strongly considered in every architectural decision.</p><h3>Serverless Architectuers Patterns</h3><p>Considering the special characteristics of serverless architectures and the crucial technical and conceptual challenges identified in dealing with FaaS, patterns of recommended practice are valuable for broader adoption. The community of developers is already active in publishing their experiences and architectural approaches in blog posts, but they are often very tailored to a specific use case. Nevertheless, some of these sources are considered in this section to emphasize practical reflections. Some fairly solid patterns with a full focus on serverless architectures were selected and explained in more detail below. When using individual patterns, the disadvantages must also be taken into account. There are rarely advantages without a drawback on the other¬†side</p><blockquote>Some rare academic research tries to cluster and summarise recurring patterns using mixed-method empirical studies. <a href="https://www.sciencedirect.com/science/article/pii/S0164121218302735">Leitner et al.</a> did a qualitative survey with 182 practitioners and observed five patterns on a very general architectural level. An in-depth study in this area was also conducted by the <a href="https://www.researchgate.net/publication/341788640_A_Review_of_Serverless_Use_Cases_and_their_Characteristics_SPEC_RG_Cloud_Working_Group">SPEC RG Cloud Working Group</a>, in which 89 serverless use cases were observed and conclusions were drawn about general types of use of FaaS. Also <a href="https://www.researchgate.net/publication/340121613_Patterns_for_Serverless_Functions_Function-as-a-Service_A_Multivocal_Literature_Review">Taibi et al.</a> published a multivocal literature review and identified a list of fairly consistent patterns categorized into the five groups ‚ÄúOrchestration and Aggregation‚Äù, ‚ÄúEvent Management‚Äù, ‚ÄúAvailability‚Äù, ‚ÄúCommunication‚Äù and ‚ÄúAuthorization‚Äù.</blockquote><h4>Function Warmer</h4><p>The cold start behavior of function calls, which can lead to long response latency, is an important aspect that has to be considered in serverless architectures. Cold starts occur because FaaS platforms discard the runtime environment of unused functions to better utilize resources. The architecture pattern <strong><em>function warmer</em> </strong>avoids this process by regularly triggering desired functions and prevents these functions from being¬†useless.</p><p>Cold starts are avoided in this way, but it must be stressed that every call also incurs additional costs. This pattern is also called function pinging. The following figure illustrates such an implementation by using a cronjob to keep certain functions warm.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*gm1ni0b8vfVMA0GLcTy1Og.png" /><figcaption>Function warmer¬†pattern</figcaption></figure><h4>Oversize Functions</h4><p>Also oversizing of functions is an observed pattern. Most FaaS platforms allocate CPU power of a function linearly in proportion to the memory configuration. Therefore, if the physical machine power is insufficient, the only way to get more CPU performance and speed up the computation, is to increase the memory allocation. Even if memory is not a bottleneck.</p><p>However, as the costs are mainly made up of both, the execution duration and the amount of allocated memory, a suitable balance needs to be found in order to not drastically increase the total¬†costs.</p><h4>Router</h4><p>Instead of using a dedicated API-Gateway, which might be cumbersome to configure, a dedicated function is implemented that receives all requests and forwards them based on the payload by using composition techniques. The exposed interface gets simplified this way. However, double billing will occur, as the routing function is active until the target function¬†returns.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*vEdj4AEAXAxwoTWdeCIkDw.png" /><figcaption>Router pattern</figcaption></figure><h4>Aggregator</h4><p>Similar to the router pattern, the <strong><em>aggregator</em> </strong>consists of one dedicated function. Instead of sharing multiple endpoints, only this aggregator function gets exposed. It calls each required service separately, aggregates all results and returns a single response to the¬†client.</p><p>However, the architect must be aware that the aggregator function represents a single point of failure and also double billing will occur. The <strong><em>aggregator</em></strong> pattern can be seen as an extension of the router¬†pattern.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*1puJ9nMITtjH_W88EYv3lw.png" /><figcaption><em>Aggregator</em> pattern</figcaption></figure><h4>Function Chain</h4><p>Composition techniques are used to circumvent the platform timeout threshold. Practitioners split up functions and chain them to prolong the maximum execution duration defined by the FaaS platform. A function passes the initial parameter and preliminary result to the next one, until the last one terminates. This pattern will lead to strong coupling between the chained functions and increase complexity.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*FBSciCgUD2qKTncw7VQorg.png" /><figcaption>Function Chain¬†Pattern</figcaption></figure><h4>Fan-out and¬†Fan-in</h4><p>Like the function chain variant, the<strong> <em>Fan-out and Fan-in</em></strong> pattern extends the execution duration threshold. However, instead of sequential function calls, the workload is divided into multiple processes. The high scalability of FaaS is exploited and functions are invoked in parallel. A storage service is often used for the final collection of the results of the individual processes and another function is finally triggered for consolidation.</p><p>With this pattern the total computation time is reduced by making use of parallelism and double billing is avoided. Nevertheless, it can only be applied to workloads that can be parallelized</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*78LAeql_6iam5viLP-h5uw.png" /><figcaption>Fan-out and Fan-in¬†pattern</figcaption></figure><h4>Externalized State</h4><p>A very commonly used pattern to handle the stateless property of FaaS is called <strong><em>externalized state</em></strong>. External storage services, such as Redis as a key-value store, are used to save and share state cross function activations. Developers need to be aware of a substantial latency overhead and high coupling.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*7lK9Jtk-FIgC9IFToybqUw.png" /><figcaption>Externalized State¬†pattern</figcaption></figure><h4><strong>Read-heavy Reporting Engine (Caching)</strong></h4><p>This pattern focuses on services with read-intense workloads and helps to overcome the downstream limitations and to reduce resulting latency by using a¬†cache.</p><p><a href="https://medium.com/@eduardoromero/serverless-architectural-patterns-261d8743020">Eduardo Romero </a>proposes to create materialized views of frequently used data in databases. Others recommend to store common responses linked to their function input using BaaS caching services such as AWS Elasticache.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/975/1*8CDU0PGUwWNXhqlIL0vrjA.png" /><figcaption>Read-heavy Reporting Engine¬†pattern</figcaption></figure><h3><strong>Conclusion</strong>üìö</h3><p>Serverless architectures can bring great benefits to developers, architects and software application owners. The argument of cost reduction is promising and development can be streamlined. However, serverless challenges need to be known by the architect and considered carefully. There are already good practices and early design patterns towards which architects can orientate themselves. Besides all the benefits, the novel architecture style will introduce more complexity to a system and there is a clear demand for better observability and visualization.</p><p>The <a href="https://github.com/cstanger/openwhisk-visualizer">OpenWhisk Visualizer (OWVIS) Project</a> is a step towards coping with this increasing complexity. OWVIS is a metaphor-based visualization tool of a Function as a Service architecture deployed on Apache OpenWhisk with the ability to make proposals to further improve a Function as a Service architecture with reference to meet serverless architecture patterns.</p><blockquote>Another upcoming blog post will be about our project so stay¬†tuned!</blockquote><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=ca5df80691c" width="1" height="1" alt="">]]></content:encoded>
        </item>
    </channel>
</rss>