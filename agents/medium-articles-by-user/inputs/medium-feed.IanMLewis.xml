<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:cc="http://cyber.law.harvard.edu/rss/creativeCommonsRssModule.html">
    <channel>
        <title><![CDATA[Stories by Ian Lewis on Medium]]></title>
        <description><![CDATA[Stories by Ian Lewis on Medium]]></description>
        <link>https://medium.com/@IanMLewis?source=rss-8660bca0444d------2</link>
        <image>
            <url>https://cdn-images-1.medium.com/fit/c/150/150/1*2YlyvrP1pkX_ztN51ZbTeg.jpeg</url>
            <title>Stories by Ian Lewis on Medium</title>
            <link>https://medium.com/@IanMLewis?source=rss-8660bca0444d------2</link>
        </image>
        <generator>Medium</generator>
        <lastBuildDate>Thu, 04 Jul 2024 15:31:14 GMT</lastBuildDate>
        <atom:link href="https://medium.com/@IanMLewis/feed" rel="self" type="application/rss+xml"/>
        <webMaster><![CDATA[yourfriends@medium.com]]></webMaster>
        <atom:link href="http://medium.superfeedr.com" rel="hub"/>
        <item>
            <title><![CDATA[Google Cloud Platform HTTP Load Balancers Explained via the CLI]]></title>
            <link>https://medium.com/google-cloud/google-cloud-platform-http-load-balancers-explained-via-the-cli-4f4d61805297?source=rss-8660bca0444d------2</link>
            <guid isPermaLink="false">https://medium.com/p/4f4d61805297</guid>
            <category><![CDATA[google-cloud-platform]]></category>
            <dc:creator><![CDATA[Ian Lewis]]></dc:creator>
            <pubDate>Mon, 18 Apr 2016 02:56:33 GMT</pubDate>
            <atom:updated>2016-04-18T02:56:33.421Z</atom:updated>
            <content:encoded><![CDATA[<blockquote>This is a post cross posted from <a href="https://www.ianlewis.org/en/google-cloud-platform-http-load-balancers-explaine">my blog</a>.</blockquote><p>The Google Cloud Platform Load Balancers are based off of technology that Google developed for our applications. There are two types of load balancers, the Network (L3) Load Balancer and the HTTP (L7) Load Balancer. The HTTP Load Balancer is global so the same IP can be used everywhere in the world, but still supports very high scalability with no warmup.</p><p>Setting up the HTTP Load Balancer is fairly straightforward in the Developers Console. You can create one in the Networks section of the console and create a load balancer. Once you’ve started creating an HTTP Load Balancer, you get a page something like this:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/923/0*cyhQ5QlDHvmfVGi9.png" /></figure><p>Each of the sections is nicely laid out and allow you to create the load balancer all at once. But there are many objects being created under the covers here, many of which only vaguely map to the UI. It can be a bit daunting to set up via the the Google Cloud CLI.</p><p>The <a href="https://cloud.google.com/compute/docs/load-balancing/http/">HTTP Load Balancer documentation</a> has some good info and diagrams that help understand how it works. But I found the diagram there to be a bit too simplistic when I wanted to set up the load balancer via the CLI. I needed to know a bit more about all the parts so I came up with this diagram.</p><p>Let’s go step by step through how to create the load balancer via the CLI. As we do that, I’ll try to point out what each of the objects we are creating correspond to in the Cloud Console so you have an idea where to look for them later.</p><h3>Health Checks</h3><p>Since most of the objects depend on one another, we will need to go from “back” to “front” starting with health checks and backend services and ending with forwarding rules. The health check object doesn’t depend on anything else so we can create it first. Even though we create the object here, it only really becomes active after we attach it to a backend service.</p><pre>gcloud compute http-health-checks create my-healthcheck --host &lt;a href=&quot;http://www.example.com&quot;&gt;www.example.com&lt;/a&gt; --port 80 --request-path=/healthz</pre><p>Here we create a health check that will connect to our app via port 80 at the /healthz URL. Note that creating the health check only tells further configuration the port and path to check but doesn’t actually send the health checks. The host parameter isn’t actually used as the host to connect to but only to set the Host header. Some apps check this header so we want them to be able to return a successful status. The instances to health check are specified later by the backend service.</p><p>Health checks are used in more than one place so they live under the Compute Engine part of the Cloud Console UI. The health checks listed here are the what correspond to http-health-checks and https-health-checks in the CLI.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/673/0*58lcEEX2_Zzfi6HL.png" /></figure><h3>Backend Services</h3><p>Next we’ll create a Backend Service. A backend-service object defines the backend VMs that actually serve the requests. The Backend Service contains a number of Backends. Each Backend is essentially a link to an instance group but has some other options attached like which port numbers to use and load balancing mode. The prefered way to set the port is via named ports on the instance group. You can set a named port for port 80 called http-port using the following command. I’m assuming you already have an instance group called my-instance-group set up. You can find out more about creating managed instance groups <a href="https://cloud.google.com/compute/docs/instance-groups/">here</a>.</p><pre>gcloud compute instance-groups set-named-ports my-instance-group --named-ports http-port:80</pre><p>Next you can create the backend service:</p><pre>gcloud compute backend-services create my-http-backend-service --http-health-checks my-healthcheck --port-name http-port --protocol HTTP</pre><p>Now that we have the health check attached to the backend service, it will connect to the instances specified by the backend service to do the health checks.</p><p>The UI shows backend-services in the “backend configuration” part of the UI.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/926/0*BM4isGqetJ0Hx9zH.png" /></figure><p>Next we have to create a Backend. A Backend specifies the instance group you want to send traffic to, and how the load should be balanced among the available instances. You can create more than one backend and a backend is generally created one per instance group. You can use this to do <a href="https://cloud.google.com/compute/docs/load-balancing/http/cross-region-example">cross-region load balancing for instance</a>.</p><pre>gcloud compute backend-services add-backend my-http-backend-service --instance-group my-instance-group --balancing-mode RATE --max-rate-per-instance 10</pre><p>This sets up a backend that sends traffic to my instance group and uses the request rate as a way to load balance. I am setting it so that each instance will get 10 requests per second maximum but you can also set this up to use CPU utilization based on your needs.</p><p>In the UI, backends are part of the backend service form. You can add any number of backends to the backend service just like can in the CLI.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/786/0*oJigciXolt4IT4-x.png" /></figure><h3>Url Maps</h3><p>Url maps are used to map hosts and urls to backend services. The url maps hold two types of objects, host rules and path matchers. Each host rule can have multiple path matchers. Each request is matched against the host rule and then the path matchers for the host rule that matches. When creating a url-maps object you specify the default backend service that is used when no host rules match.</p><pre>gcloud compute url-maps create my-url-map --default-service my-http-backend-service</pre><p>If you have only one backend service then this one command is usually enough since all traffic can be sent via the default service. However if you have multiple backends you can set the up based on host or url. A host rule can have multiple path matchers but the host rule must have at least one path matcher so we create the path matcher and host rule at the same time.</p><pre>gcloud compute url-maps add-path-matcher my-url-map --path-matcher-name my-www-path-matcher --new-hosts &lt;a href=&quot;http://www.example.com&quot;&gt;www.example.com&lt;/a&gt; --default-service my-http-backend-service</pre><p>You can specify that requests with a different host go to a separate backend service as well.</p><pre>gcloud compute url-maps add-path-matcher my-url-map --path-matcher-name my-api-path-matcher --new-hosts api.example.com --default-service my-api-backend-service</pre><p>Like the url-maps itself you specify a default service if the host rule matches but no path rules match. You can also specify different backend services be used based on the path.</p><pre>gcloud compute url-maps add-path-matcher my-url-map --path-matcher-name my-path-matcher --new-hosts &lt;a href=&quot;http://www.example.com&quot;&gt;www.example.com&lt;/a&gt; --path-rules=”/api=my-api-backend-service,/other=my-other-backend-service” --default-service my-http-backend-service</pre><p>In the UI the URL maps, host rules, and path matchers are specified in the “Host and path rules” section.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/982/0*i5-OFzyq-DhBbEza.png" /></figure><p>The first row contains the default service which is used when a request doesn’t match a host rule/path matcher combination. The other rows contain the host rule/path matchers.</p><h3>Target Proxies</h3><p>Target HTTP Proxies and Target HTTPS Proxies are objects that connect one or more forwarding rule to a URL map.</p><p>Target Proxies terminate the connection to the user so you specify the SSL certificate to use when you are using HTTPS. SSL certificates are created like so:</p><pre>gcloud compute ssl-certificates create my-cert --certificate /path/to/cert.pm --private-key /path/to/key.pm</pre><p>You can then use the certificate to create the HTTPS proxy.</p><pre>gcloud compute target-https-proxies create my-https-proxy --url-map my-url-map --ssl-certificate my-ssl-certificate</pre><p>You still need to create one but at this point I felt that Target Proxies made things more complicated than it needs to be since you almost always use one forwarding rule per target proxy for HTTP load balancers.</p><h3>Forwarding Rule</h3><p>Forwarding rules are final object we need to create. These are the objects that your are actually billed against. The Forwarding Rules map the IP address for your load balancer to the Target Proxy that will handle the requests. First we will need to create our IP address though. We will need a global, rather than regional, IP address for our HTTP load balancer.</p><pre>gcloud compute addresses create my-address --global</pre><p>Then we can create our forwarding rule. Notice that we will need to put in the actual IP address that we just created rather than the IP address name. Not also that you can only put a single port as the — port-range option and that we need to add the — global option.</p><pre>gcloud compute forwarding-rules create my-https-forwarding-rule --global --address 123.123.123.123 --ip-protocol TCP --port-range 443 --target-https-proxy my-https-proxy</pre><p>Many applications will want to redirect users that access <a href="http://www.example.com/">http://www.example.com/</a> to <a href="https://www.example.com/">https://www.example.com/</a>. This is a pretty common use case that is not supported by the load balancer. You need to create a totally separate Target HTTP Proxy and Forwarding Rule for HTTP. You essentially need to have two load balancers to handle the traffic, and then actually redirect users in your application.</p><p>Notice that we put the same IP address in for the HTTP Forwarding Rule. This makes is so that we can listen on port 80 and on port 443 at our IP address.</p><pre>gcloud compute target-http-proxies create my-http-proxy --url-map my-url-map gcloud compute forwarding-rules create my-http-forwarding-rule --global --address 123.123.123.123 --port-range 80 --target-http-proxy my-http-proxy</pre><p>Now that you’ve created a forwarding rule, it will show up in the “Load balancing” section of the developers console.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/880/0*LFAsVpNQiXFwc7tk.png" /></figure><h3>The Advanced View</h3><p>There is also an “Advanced View” that allows you to view the objects in a format that is much closer to the CLI counterparts. There are tabs for each of the major objects as well as a couple for the network load balancers.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/661/0*WTnx-_O_iRhsGAz5.png" /></figure><p>The objects that make up the HTTP(S) Load Balancer and the commands that you need to run to set it up on GCP are not totally obvious given how you create a in the UI. But hopefully this post has shed some light on how they map together. Be sure to also check out the <a href="https://cloud.google.com/compute/docs/load-balancing/http/">HTTP Load Balancer documentation</a> it has lots more info and guides like how to do some more complex setups like <a href="https://cloud.google.com/compute/docs/load-balancing/http/cross-region-example">cross-region load balancing</a> and <a href="https://cloud.google.com/compute/docs/load-balancing/http/content-based-example">content based load balancing</a>.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=4f4d61805297" width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/google-cloud-platform-http-load-balancers-explained-via-the-cli-4f4d61805297">Google Cloud Platform HTTP Load Balancers Explained via the CLI</a> was originally published in <a href="https://medium.com/google-cloud">Google Cloud - Community</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Deploying Go Servers with Kubernetes on Container Engine]]></title>
            <link>https://medium.com/google-cloud/deploying-go-servers-with-kubernetes-on-container-engine-3fee717a7e2a?source=rss-8660bca0444d------2</link>
            <guid isPermaLink="false">https://medium.com/p/3fee717a7e2a</guid>
            <dc:creator><![CDATA[Ian Lewis]]></dc:creator>
            <pubDate>Thu, 16 Jul 2015 05:07:27 GMT</pubDate>
            <atom:updated>2015-07-16T05:07:27.827Z</atom:updated>
            <cc:license>http://creativecommons.org/licenses/by/4.0/</cc:license>
            <content:encoded><![CDATA[<blockquote>Note: Cross posted on <a href="http://www.ianlewis.org/en/deploying-go-servers-kubernetes">my blog</a>.</blockquote><p>I was trying to get a Go app running on Container Engine and couldn’t quite<br>find what I was looking for. There are guides out there about how to use Go and Docker, and how to use Kubernetes but but not many about Go apps and Container Engine. I also found it easy to deploy apps but most guides lacked information on best practices for how to maintain apps through regular upgrades so I decided to research it and write a post about it myself.</p><p>Be sure to check out the <a href="https://cloud.google.com/container-engine/docs/">Container Engine documentation</a> for details about the concepts and commands used.</p><p>This post is a continuation of the <a href="https://blog.golang.org/docker">Deploying Go servers with<br>Docker</a> article on the Go blog. Make sure you run through building the Docker image.</p><h3>Pushing the Docker Image to Google Container Registry</h3><p>You will need the gcloud tool so make sure you have the <a href="https://cloud.google.com/sdk/#Quick_Start">Google Cloud<br>SDK</a> installed. Next you’ll need to <a href="https://developers.google.com/console/help/#creatingdeletingprojects">create a project on the Google Developers<br>Console</a>. Make note of the project id.</p><p>Set up your gcloud tool with the right config. Replace <em>&lt;project-id&gt;</em> below<br>with your project id. Replace <em>&lt;zone&gt;</em> with the zone of your choosing:</p><pre>$ gcloud config set project &lt;project-id&gt;<br>$ gcloud config set compute/zone &lt;zone&gt;</pre><p>Once you have that done you will need to tag the<br>image using docker.</p><pre>$ docker tag outyet gcr.io/&lt;project-id&gt;/outyet:v1</pre><p>This will set the repository and tag it with the version ‘v1’. Next push the<br>image to the registry. You may get warnings about installing the `preview`<br>components. Just say ‘yes’ to install them when asked.</p><pre>$ gcloud preview docker push gcr.io/&lt;project-id&gt;/outyet:v1</pre><h3>Kubernetes Configuration</h3><p>We will create a <a href="https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/replication-controller.md">replication controller</a> and <a href="https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/services.md">service</a> for our app.</p><p>The replication controller configures how our app will be run and maintained in Kubernetes and the service allows our containers to be accessed as one logical service/app. Create a <em>outyet-rc.yml</em> file with the contents below. We will use the new <em>v1</em> version of the API:</p><pre>kind: ReplicationController<br>apiVersion: v1<br>metadata:<br>name: outyet-v1<br>spec:<br>  replicas: 3<br>  selector:<br>    name: outyet<br>    version: “1”<br>  template:<br>  metadata:<br>    labels:<br>      name: outyet<br>      version: “1”<br>  spec:<br>    containers:<br>      — image: gcr.io/&lt;project-id&gt;/outyet:v1<br>        name: outyet<br>        ports:<br>          — containerPort: 8080<br>            hostPort: 8080<br>            protocol: TCP</pre><p>Next we’ll create a service for our app. Create an `outyet-service.yml` with<br>the contents below:</p><pre>kind: Service<br>apiVersion: v1<br>metadata:<br>  name: outyet<br>  labels:<br>    name: outyet<br>spec:<br>  ports:<br>    — port: 80<br>      targetPort: 8080<br>      protocol: TCP<br>  selector:<br>    name: outyet<br>  type: LoadBalancer<br></pre><h3>Deploy the Container Engine Cluster</h3><p>Next we’ll deploy our container engine cluster. We’ll use the gcloud tool again. You may get<br>warnings about installing the `alpha` components. Just say ‘yes’ to install them when asked.</p><pre>$ gcloud alpha container clusters create outyet<br>$ gcloud config set container/cluster outyet</pre><h3>Create the Replication Controller</h3><p>After the cluster is created we can deploy the app. First we will create the replication controllers:</p><pre>$ gcloud alpha container kubectl create -f outyet-rc.yml</pre><p>It will take a few minutes for the pods to come up. You can see if the pods are<br>ready using the following command:</p><pre>$ gcloud alpha container kubectl get pods</pre><p>The pods will say their state is `Pending` at first but will change to<br><em>Running</em> when they are ready.</p><h3>Create the Service</h3><p>Create the service with the following command.</p><pre>$ gcloud alpha container kubectl create -f outyet-service.yml</pre><p>After the service is created we can see that it is created by viewing the<br>output of this command:</p><pre>$ gcloud alpha container kubectl get services</pre><p>The service uses the <em>LoadBalancer</em> feature of Container Engine to set up a<br>network loadbalancer to our service. We can get the external IP of the service using the following command:</p><pre>$ gcloud compute forwarding-rules list</pre><p>This will show the IP address of our service. Make note of the IP address.<br>Finally we can create a firewall rule to allow access to our nodes:</p><pre>$ gcloud compute firewall-rules create outyet-http — allow tcp:80 — target-tags k8s-outyet-node</pre><p>Now we can view the app at <em>http://&lt;IP Address&gt;/</em></p><figure><img alt="" src="https://cdn-images-1.medium.com/max/679/1*-uFvFULa3QEtQqE1SuGeCQ.png" /></figure><h3>Upgrading the App</h3><p>Go 1.4 is already out yet so app isn’t really exciting. Let’s update it so it<br>checks for Go 1.5. Lets override the CMD for the Dockerfile so it looks like this:</p><pre>FROM golang:onbuild<br>CMD [“go-wrapper”, “run”, “-version=1.5”]<br>EXPOSE 8080</pre><p>Next we will build, tag and push the updated docker image:</p><pre>$ docker build -t outyet .<br>$ docker tag outyet gcr.io/&lt;project-id&gt;/outyet:v2<br>$ gcloud preview docker push gcr.io/&lt;project-id&gt;/outyet:v2</pre><p>Next lets update all the places it says <em>v1</em> in our <em>outyet-rc.yml</em> and change it to <em>v2</em>.</p><pre><br>kind: ReplicationController<br>apiVersion: v1<br>metadata:<br>  name: outyet-v2<br>spec:<br>  replicas: 3<br>  selector:<br>    name: outyet<br>    version: “2”<br>  template:<br>    metadata:<br>      labels:<br>        name: outyet<br>        version: “2”<br>    spec:<br>      containers:<br>        — image: gcr.io/&lt;project-id&gt;/outyet:v2<br>          name: outyet<br>          ports:<br>            — containerPort: 8080<br>              hostPort: 8080<br>              protocol: TCP</pre><p>Next do a rolling update of our replication controller <em>outyet-v1</em> to our new<br><em>outyet-v2</em>:</p><pre>$ gcloud alpha container kubectl rollingupdate outyet-v1 -f outyet-rc.yml — update-period=10s</pre><p>This should take about 30 seconds to run as we have 3 replicas and we’ve set<br>the update period as 10 seconds per replica.</p><p>After that runs we can refresh our app again to see if Go 1.5 is out yet :)</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/679/1*AYqpJF0oNKADydUCUgnOCA.png" /></figure><h3>Cleanup</h3><p>Make sure you delete your cluster so you don’t get charged too much money :)</p><pre>$ gcloud alpha container clusters delete outyet</pre><h3>Conclusion</h3><p>I really think containers are the way everyone will be developing apps in the future so hopefully that gave you an idea of how you can deploy a Go app and upgrade it using Container Engine. As a next step try out some of the many <a href="https://github.com/GoogleCloudPlatform/kubernetes/tree/master/examples">example apps</a> available in the Kubernetes repo.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=3fee717a7e2a" width="1" height="1" alt=""><hr><p><a href="https://medium.com/google-cloud/deploying-go-servers-with-kubernetes-on-container-engine-3fee717a7e2a">Deploying Go Servers with Kubernetes on Container Engine</a> was originally published in <a href="https://medium.com/google-cloud">Google Cloud - Community</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Learning a Language as Muscle Memory]]></title>
            <link>https://medium.com/@IanMLewis/learning-a-language-as-muscle-memory-16332f7c7666?source=rss-8660bca0444d------2</link>
            <guid isPermaLink="false">https://medium.com/p/16332f7c7666</guid>
            <dc:creator><![CDATA[Ian Lewis]]></dc:creator>
            <pubDate>Sun, 02 Jun 2013 14:57:19 GMT</pubDate>
            <atom:updated>2013-06-02T14:57:19.884Z</atom:updated>
            <content:encoded><![CDATA[<figure><img alt="" src="https://cdn-images-1.medium.com/max/699/0*uTrb8PIu3Ltmh9D7.jpeg" /></figure><p>I learned a lot from learning a second language. I started learning Japanese on my own and moved to Japan several years ago. I now work at a Japanese company where I spend most of my day speaking and writing Japanese.</p><p>Most people think about learning a second language as a kind of <a href="http://en.wikipedia.org/wiki/Rote_learning">rote learning</a>. You memorize the vocabulary and grammar of a language and when the time comes to use it, you recall the vocabulary and grammar from your memory and use what you remembered to form a coherent thought or sentence. You do this in the same way to deconstruct things that other people say. Many language learning methods focus on this aspect of learning a language. <a href="http://en.wikipedia.org/wiki/Spaced_repetition">Spaced Repetition</a> is one of them and is an extremely good way of remembering vocabulary and facts.</p><p>However, after interacting with many people living in Japan and attempting to learn the language, I felt that too many people focus on this area too much. Their knowledge of the language constructs, vocabulary and culture sometimes exceeds my own, but their fluency in conversation leaves something to be desired. How is that?</p><p>I’ve  come to believe that learning a language is as much about <a href="http://en.wikipedia.org/wiki/Muscle_memory">muscle memory</a> as about rote learning. Speaking a language is a real time activity. You need to be able to respond to a query, ideally, in about a second, and absolutely within a few seconds. Getting that kind of speed requires practice. You need to be able to understand commonly used phrases quickly, and react properly when you don’t know how to respond. The only way to really get better at conversation is to talk to people. The more the better.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=16332f7c7666" width="1" height="1" alt="">]]></content:encoded>
        </item>
    </channel>
</rss>